,video_id,title,channel,question,transcript
0,5jBVYvHeG2c,Brownian Motion - The Physics of Randomness,Up and Atom,brownian motion,"- This video was made possible by CuriosityStream, get access to my streaming video service Nebula. When you sign up the CuriosityStream with the link in the description. (upbeat music) - These are pollen particles suspended in water as seen under a microscope, notice how they jiggle around. In fact, they never stop jiggling. Why? The answer to this question helped prove the existence of atoms, figure out the movement of stars and predict the rise and fall of the stock market. Hi there, welcome to Up and Atom. I'm Jade, so how could something that we see under a microscope help us understand gigantic stars way out in the universe, or even stranger, a totally man-made system like the stock market? Well, the story begins in 1827, when Robert Brown was hired by the British museum to help form the new Botany Department. One of his interests was how pollen could be used to classify plants. One day Brown wanted to look at some pollen under the microscope. So he put a drop of water on a microscope slide and added pollen to it, like always the pollen wiggled and vibrated in the water. But for the first time Brown wondered why? He got swept away in this question and totally forgot about his task of classifying plants. Let's see if we can figure it out. When we watched the pollen for a while, the small vibrating movements seem to add up causing it to drift and zigzag through the water. What is a typical phenomenon that may cause something in water to move around? Well, one I'm sure you're familiar with is a current. Brown thought maybe the surrounding air was causing a current which was moving the pollen. A pretty good guess, but there's a problem. A current would push all the pollen in one direction and the pollen is moving randomly. So that's not it. Brown's next thought was maybe it has something to do with water evaporation. To test this, he needed a way to see what would happen if evaporation stopped. So he suspended a drop of water with pollen particles in it, inside oil, keeping the water trapped, but the jiggling was still there. So water evaporation without. Brown knew the plant the pollen came from was alive. So he wondered if perhaps the pollen might also be alive and actively swimming around like sperm. This might sound silly to us now, but what would you think if you put something under the microscope and it never stops jiggling and moving around? I would definitely think something spooky was going on. But when we repeat this experiment with things we sure are definitely not alive. The jiggling is still there. It's not just limited to pollen. So that wasn't it either. The defining feature that all of the jiggling specimens have in common is that the motion is totally random. Eventually Brown moved on to other experiments without solving the problem. He was probably having a tough time convincing his colleagues in the Botany Department that looking at a piece of pollen under a microscope was really the best use of his time. But we are not going to give up. Now, before we go on let's get a little context for some of the scientific views at the time. Atoms had not yet been discovered. And the popular understanding of liquids and gases was that they were densely packed with particles and surrounded by an invisible substance called caloric fluid, scientists thought that when they warmed up a liquid or compressed a gas that caloric fluid was flowing into the system. Then when they let it cool the caloric fluid would flow out. But some scientists were working on a different idea which said that all those changes in pressure and temperature could be accounted for by one simple thing, a small amount of particles constantly moving and bouncing around. Now, from the perspective at the time this was a pretty strange idea. How could a relatively small number of particles fill up a whole space, the way a gas expands to fill up a container and how do they keep moving even after being left alone for a long time? Shouldn't they just quickly settle down and lose all their energy the way you see a cloud of dust settle, but there was an even bigger problem. The theory said that the particles were so small that even the best microscopes at the time wouldn't be able to see them. How was one supposed to experimentally prove a theory that couldn't be seen? Well, it was Einstein who came up with a solution to the problem and in doing so solved Brown's pollen mystery as well. He figured that even if you couldn't see the tiny particles themselves you should be able to describe how they interact with something larger that you can see, like wind. We can't see it, but we know it's there because we can see its effect on other things. This is my mom and she is going to help demonstrate this idea. Here we have an amp connected to an electric bass guitar. Here I'm putting in some polystyrene balls which represent water molecules and a giant red bull which represents the pollen particle. When we put the amp on a low setting and play the guitar, it'll vibrate causing the balls to bounce and jiggle around. Look familiar? Now let's turn it up. This represents an increase in heat. Hit it mom, the more energy put into the system the more violently the balls jiggle around. So if these tiny particles or atoms did exist, it would not only explain how increases in temperature effect pressure and density in liquids and gases. It would also explain why Brown's pollen never stopped jiggling around. Thanks mom. This was Einstein's idea. A nice theory, but how do we know it's true? Well, let's try it with some water and something else that we can see. Ink. Here I have a glass of cold water and a glass of hot water. If water really is made up of tiny atoms which vibrate faster, if more heat is applied how do you expect that the ink molecules will behave in each glass? Take a moment here to pause the video and see if you can guess how a drop of ink will behave in each glass. Ready? (gentle music) How did you go? There's a massive difference. The ink molecules disperse much faster and much more violently in the hot water. This is exactly what we should expect based on Einstein's theory. As the hot water molecules are vibrating faster and more energetically than the cold water molecules. This theory was experimentally proven by a French physicist named Jean Perrin who won a Nobel prize for his work. Not only did this debunk caloric theory but is considered the major turning point for atomic theory where even the scientists who were most skeptical of this constantly moving tiny particle idea were converted. This laid the basis for everything we now know about atoms. Lots of modern technology from the device you're watching this on to nuclear power were made possible by these fundamental insights into the microscopic world. So big thanks to Robert Brown for getting obsessed with jiggling pollen when he should have been classifying plants. Because of his pioneering work this phenomenon of tiny atoms pushing around a larger particle is called Brownian motion. Brownian motion is most famous for its role in proving atomic theory, but it's turned out to be useful in many other fields, including astrophysics and finance. Now, this might seem weird because how could the random motion of pollen being hit by millions of water molecules possibly apply to giant stars and man-made financial systems? Well, what is Brownian motion really describing? Behind the pollen and the atoms, it's one big thing being affected by lots and lots of smaller random forces. So let's imagine that our grain of pollen is in fact a giant star. What in the universe might surround it that could make it jostle around like the water molecules? As it turns out, the combination of lots of little pulls from the gravitational field of smaller stars can jostle around a type of large star called a massive binary. A star might not be literally hit by thousands of smaller objects from all sides but there are still many smaller random forces being applied to a larger object. The force is just gravitational rather than being physically hit. Just like with the water molecules, the smaller stars are not coordinated with each other. So the forces they exert on the massive binary add up to random motion. What about for financial markets? This is probably even weirder because pollen jostle and (indistinct), although massively different in scale, a naturally physical phenomenon. The stock market is a purely human enterprise. What forces could possibly simply act on the price of a stock? Well, imagine there are 10 apples available to buy, the price of those apples will be much higher if 10,000 people want to buy an apple than if just one person wants to buy an apple, that seems pretty straightforward but what determines how many apples are available or how many apples people want? The number of available apples could rise if the weather is good for apple growing or fall if there is a pest invasion. Those things aren't easy to predict and can be considered random factors for all intents and purposes. That was a very simple example, but in real financial markets supply and demand depends on lots of different things including a plethora of human emotions, greed and fear, hope and defeat, elation and despair, news and sentiment. The state of the world and many more. Forces on the stock market are more abstract than water molecules and gravitational pull. But the mathematics of Brownian motion can still be applied. It's still a lot of smaller random forces acting on a larger object. Brownian motion isn't about pollen, stars, or the stock market, the power of science lies in its ability to pull out all of the abstract elements that different phenomena have in common and to using the solution to one problem to solve many. If the same mathematics can be used to solve many different phenomena, this leads to a very interesting question, is the universe mathematical or is math a language we've invented to describe it? Is math invented or discovered. I've made a video discussing these very questions over on Nebula, which you can watch for free with this link. So Nebula is an educational streaming platform made by your favorite educational creators like Adam Neely (indistinct) real engineering went over productions, Brian Craft and many more. We created Nebula so we could have more creative freedom to bring our creations to life. For example, I felt that this question of is math invented or discovered needed more than a month of work to do it justice, which is about what I spend on my regular YouTube videos. Because of Nebula, I was able to spend four months researching the topic and get help in the production process to really make it a special experience for you guys. If you like the video, consider subscribing to Nebula to get access to and support the creation of more videos, just like it. It's only $3 a month, but our friends at CuriosityStream are offering a special deal where if you sign up with them you get Nebula for free. CuriosityStream is a documentary streaming service with names like David Attenborough and Stephen Hawking. So by signing up with them, you're getting two educational streaming services for the price of one, that is literally hundreds of hours of awesome things to learn, but less than $20 a year. If that sounds like something you're interested in, go to curiositystream.com/upandatom. You can find that link and the link to that is math discovered or invented video in the description. Thank you for watching and I'll see you in the next episode. Bye. (upbeat music)"
1,W7WzxpI3eWE,How Brownian Motion Helped Prove the Existence of Atoms,Journey to the Microcosmos,brownian motion,"This episode is sponsored by Endel,   an app that creates personalized  soundscapes to help you focus,   relax and sleep.The first 100 people to click our  description link will get a one week free trial. It’s probably hard to ignore the very obvious  green algae taking up most of your screen.   But for the moment, I want you to try. Look away  from the closterium and instead, shift your focus   to the area that surrounds it. At first, it may  not seem that interesting. It’s just a sea of   dark blue, interrupted only by tiny little dots. But unlike the completely static closterium, those   tiny little dots are wiggling around in  frantic, uncoordinated directions like they’re   dancing to a million different soundtracks  played at once. There are organisms in the   world of the microcosmos that move in concerted,  directed ways, but this is definitely not that.  Now let’s focus on the closterium. Look towards  the tip of the algae, where there are round barium   crystals wiggling around in the same random  way that those particles we saw before were.  We’re going to see that type of motion over  and over again today because it’s all over the   microcosmos, found in and around many different  types of organisms. And this kind of random motion   may seem almost too trivial to discuss, leading  at best to an end where I mull over the way that   randomness seems to pop up everywhere like some  kind of unifying force that shapes our lives   through millions of tiny coincidences. Except, well, there’s no point waiting   until the end to say all that because the  reason we want to talk about this weird,   wiggling motion is that this randomness really  does tie us together, not metaphorically, but   very, very literally and physically. This motion  that you see is a proof of something fundamental   not just to life, but to existence  itself. This movement is proof of atoms.  It’s easy to take the existence of atoms for  granted now, in the same way that it’s easy to   take the existence of microbes for granted. Once  you know about them and how they shape the world,   and you've been told about them since you were a child, it’s impossible to see the  world as existing without them.  But our knowledge of both is relatively recent,   even if it’s built on work that spans  millennia. And just as the microscope has been   essential to our understanding of microbes, it has  played an important role in understanding atoms.  Long before the existence of the  microscope though, there was an idea.   In the fifth century BCE, a Greek philosopher  named Democritus proposed that if you kept   breaking matter down further and further, you  would eventually reach something that could no   longer be broken down. That indivisible thing was  what he called atomos, which meant “uncuttable”. Democritus’ theory was in opposition  to the ideas of Aristotle and Plato,   who believed that the world was composed of  four basic elements: earth, wind, air, and fire.  So what does Democritus have  to do with the tiny little   wobbles of the pigments inside this stentor? For that, we have to flash forward to 1827.   This was an exciting time for anyone interested in  diving deep into what matter was made of. The end   of the 18th century had seen important advances  in our understanding of matter. And in 1803,   the scientist John Dalton drew upon these  ideas to propose that each chemical element   could be described by a particular atom. The atom became a useful tool in developing new   theories about how our world is built, and 19th  century physicists used it to describe a theory of   gasses that assumed they were composed of many,  many tiny particles constantly moving around.  But these theories weren’t proof. If anything,  they raised more questions about how to think   about atoms. Should we think of atoms as  just some kind of mathematical metaphor,   or were they something real? And how could we  find proof of something as unseeable as an atom?  The answer, it would turn out, would come  thanks to a botanist named Robert Brown.  Brown wasn’t setting out to solve the  problem of atoms. It was the summer of 1827,   and he was trying to clear up some questions  he had about the tiny particles that burst   out of pollen grains like this one. So he did what we’re doing right now:   he brought out his microscope, and looked at  some tiny things under it. While we didn’t have   those pollen particles on hand, we imagine that  what he saw was similar to these oil droplets,   which came from the body of a dying copepod. He said simply, “While examining the form of   these particles immersed in water, I observed  many of them very evidently in motion,”.   Curious about this motion, Brown proceeded to do  a number of different experiments. He looked at   pollen from other plants and saw the same motion.  He looked at pollen from dead plants and saw the   same motion. He even moved on to inorganic  materials like rocks and saw the same motion.  In water, everything wiggled, even if it wasn’t  living. And that meant the motion wasn’t something   biological, it was rooted in something else. These random movements are what we now call   Brownian motion. And in the decades that followed  his observation, physicists began to study it   in earnest so they could understand  the forces that shaped the movement.  For example, one scientist noted that smaller  particles exhibited faster motion compared to   larger ones, which you can see at play here  in the crystals lying within this amoeba,   with the larger crystals moving more  slowly compared to the smaller ones5.  But Brownian motion’s biggest impact would  come in 1905 when a scientist theorized   that the movement of the particles Brown  had watched was the result of other smaller   particles colliding into them. That scientist, you  probably know the name of, it was Albert Einstein. And those smaller particles were  water molecules, composed of   atoms that are packed with energy. And because of  that energy, the water molecules are constantly   moving and colliding. Sometimes they collide with  each other. And sometimes they collide into other   larger particles, which move erratically in  response. That is Brownian motion, a movement   shaped by atoms and their kinetic energy. Einstein’s theories were built on equations,   but they provided a framework that would allow  experimentalists to use Brownian motion as a   way to see atoms and their energy at work. And  ultimately, it was the French scientist Jean   Perrin who put these theories to the test, using  a new microscope called the ultramicroscope to   not only study Brownian motion and confirm the  equations that drove Einstein’s theory, but also   to estimate the size of water molecules. All of that discovery was made possible because a   botanist wanted to study some pollen.  Robert Brown was operating in a realm   that is familiar to us here on Journey to the  Microcosmos. He was exploring an invisible world.  But what he studied and what he described helped  us find an even more invisible world, one that was   still invisible under his microscope, except  that it was responsible for everything he was   seeing, not just the motions of the pollen grains,  but the pollen grains themselves and anything else   that was under his microscope, outside his  microscope, and even the microscope itself.  What he found in those wiggles—what you’re seeing  now in the same motion more than a century later,   is an invisible world that  built an entire universe.  Thank you for coming on this journey with us as  we explore the unseen world that surrounds us.  And thank you again to Endel  for sponsoring this episode.  Endel is an app that takes  everything we know about sound,   combines it with technology, and creates  personalized soundscapes to help you focus,   relax, and sleep.Their app was named the Apple  Watch App of the Year in 2020 and they have a   brand new soundscape called Wind Down that  they made in collaboration with James Blake.   The goal of Wind Down is to help you  transition from an active day to a   calmer state, so it’s great just before bed too. Sound has a direct impact on your physical and   mental wellbeing, and by adapting in  real-time to things like your location,   weather, and heart rate, Endel creates simple,  pleasant sounds that can help to calm your mind.  If you’re interested in trying out Endel, just  be one of the first 100 people to download it   using the link in the description and you  will get a free week of audio experiences!  Thank you to all the people whose  names are on screen right now.   They are our Patreon patrons. We love what we  do at Journey to the Microcosmos, this team   is just delighted to be able to do it, and I am  so glad that other people love it too because   without them we would definitely not be able to  do it, so thank you so much to all of our patrons.   And if you are interested in becoming one, you  can check it out at Patreon.com/JourneytoMicro.  If you want to see more from our  master of microscopes, James Weiss,   you can check out Jam & Germs on Instagram,  and if you want to see more from us,   there is always a subscribe  button somewhere nearby."
2,V7VtOa8pHno,Brownian Motion,Physics Videos by Eugene Khutoryansky,brownian motion,"If we place tiny particles in a liquid or gas, and we examine them under a microscope, we will see that these particles exhibit random fluctuations.  The movement never stops, and the motion of a particle has no correlation to its past motion or to the motion of the neighboring particles.  This is called Brownian motion, after the botanist Robert Brown. When Robert Brown observed this phenomenon with plant pollen immersed in water in 1827, he initially believed that this motion was due to the fact that the plant cells are alive. However, he then tested the pollen from plants which have been dead for over a century, and he still saw the same results. Later, it was shown that the same results occur even with particles such as chips of granite immersed in a fluid. We know now that the reason for Brownian motion is the collisions with the random vibrations of the atoms and molecules of the fluid. In fact, Brownian motion helped provide evidence for the existence of atoms and molecules. Although here, we show the immersed particles to be the same size as the molecules of the fluid, Brownian motion will still occur even if the immersed particles are much larger than the molecules of the fluid. The molecules of the fluid are in constant motion, and collisions cause each of the immersed particles to undergo small random fluctuations. These random fluctuations cause the immersed particles to slowly diffuse throughout the entire fluid. At higher temperatures, these random vibrations are much faster, and the immersed particles will spread out through the fluid more rapidly. The mathematics we have developed for studying Brownian motion can be used to study many different types of phenomena. This includes phenomena such as the diffusion of pollutants through the atmosphere, The diffusion of calcium through living bone tissue, And the diffusion of electrons and holes inside a semiconductor. Although the motions are random and we therefore don’t know the position of each particle, we can nevertheless use statistical analysis to determine the probability distribution. If all the particles start out at one location, then over time, the probability distribution for the positions will be a Bell Curve. The Bell Curve will always remain centered on the original location of the particles, but the standard deviation of the Bell Curve will grow with time, meaning that the particles will be more and more spread out. A Bell Curve is often referred to as a ""Gaussian distribution"" or ""Normal distribution."" Bell Curves are very important to the study of many phenomena in physics and in other disciplines.  This is discussed in detail in the video titled: ""Probability – Quantum and Classical."""
3,4-Tas6Uw_OQ,Brownian Motion-I,Probability and Stochastics for finance,brownian motion,"So if you go to the stock market and look at the price of say a favourite company’s share. So what you would observe is the following. So if the horizontal axis is the time axis and if this is the price axis it tells you what is the price then you will see starting from a certain time price  you will see some zigzagging motions like this. So you observe it up to time T and you observe this zigzagging motion. This is of course random. Nobody knows what is the next price is. So if a particular scenario evolves, you have a particular path. This is called a sample path. So if another scenario evolves, if another scenario evolves there would be another path, for example it could be like this. The stock price is going down down down down and you are in a bad shape and then it again climbs up and again it falls down down down and again then again climbs up. So under a different scenario it has a different path. So it is sample path 1 it is sample path 2. So it is what type of scenario one evolves. Now of course you can ask me what is this term scenario that you are talking about, what is the meaning of this goddamn scenario? We will come to this very soon. But how do I model such zigzagging paths, what way to model it. Is there any mathematical way to say that us or can I construct the stochastic process whose sample paths are represented in this form? Let us do, to do that we need to study what is called Brownian motion. Brownian motion is a type of stochastic process which will help us to model stock prices at the end. So the whole term Brownian motion comes from the name of Robert Brown who first studied the movement of pollen grains in water and he found that they were having a zigzag haphazard movements. But it is not so immediately apparent that you can just start writing about this particular stochastic process. We need to have some more idea and built upon some simpler stochastic process. So we will begin by introducing what is called symmetric random works. Where there are only 2 possibilities you can either go up or down that is like a coin toss head or tail and that here I can have infinite such possibilities, infinite such sample paths and there are infinite possibilities also. Here also we will have infinite possibilities but generated out of only 2 possibilities. So symmetric random walk. So when you take a fair coin and then you keep on repeatedly tossing it. So it is a so this is a stochastic process which I will write in short form now as stochastic process generated by repeated tosses of a fair coin okay and if you look at it very carefully what I mean by this? So you start tossing the coin so repeatedly you are tossing omega 1 omega 2; so omega 1 is either head or tail; omega 2, omega 3, omega 4, 5 and so and so forth. Suppose you have here head, head, tail, tail, head, head, head, tail, tail, tail and it goes on. So this is one particular scenario that has evolved. You could have another scenario say omega bar which is consisting of say omega 1 bar, omega 2 bar, omega 3 bar, omega 4 bar, omega 5 bar, it could be something like this; tail, tail, head, head, head, tail, tail, tail, head, head, head and so on. So these 2 are different scenarios and these 2 each would generate 2 different sample paths. So how do we generate this symmetric random walk? So these are 2 different scenarios, 2 different scenarios. Now construct a random variable Xj which takes the value 1 if j is equal sorry if omega j is equal to head and takes the value -1 if omega j is equal to tail if tail appears and 1 if head appears. So now you define a stochastic process, define a new stochastic process Mk, k=0 to infinity or let us we can need not bother we can also fix it after some time. It could be some time capital say K is say 25 something here 25 or 30 whatever. But in general it is alright to take plus infinity just a sequence where M k is given as follows. Each of these M ks are calculated by starting from M 0 equal to 0. M k is equal to j is the sum from j from 1 to k to X j. So let us see what would happen if one particular scenario like this evolves. Let us see then what is the sample path of this. This symmetric random walk is also called a drunkards walk. So somebody has had a good drink and he has become drunk and if you look at his walk so a drunkard would walk like this if I am here so I start from here then I can just go like this and he goes like this just it is just or like this you know I am coming here and then I am going there something like this. So this sort of thing you will immediately observe as I start say checking out with this scenario. So here is my k and here is my M k value. Now the first one here has turned out to be head. So M0 is 0. Let me write -1, -2, -3 and so on -4 here 1 2 3 4 and so on and of course here also you have to have k values which is 1 or maybe 1 2 3 4 5 6 7 8 9 10 and so and so forth. So M0 is 0 this is 0 is 0. Now you toss a coin and you have head. Omega 1 is head so you go up by +1 because X j will take +1 because m1 is just X 1 so here is the value of M1 this is your M1 so you join the M0 and 1 by line so 0 is M0 and then you again had head so M2 is again 1. I am looking at this scenario M2 is you go by 1 so it is 1+1 now 2. So M2 is 2. So you join again by this line. But M 3 is tail so you will drop by 1 so it will be -1 so it will again drop back to the point 1. So this is your M2 and this is M3 and then omega 4 is again tail so it drops back to 0 again you -1 subtract. So this is your M4 0. Again then you have head for omega 5 say so here you have omega 6, omega 7, omega 8, omega 9, so for M4 you have tail you have come to 0 again then it goes up again for M it goes to plus 1 again. So this is your M5. Again, it goes up to 2 M6 but then you have tail again so M7 comes down to +1. Again, you have tail so M8 comes down to 0 because you are adding up everything. At every step you are going up or down. So you add up in this fashion and you move like this. So M8 I have here omega 8 it is again omega 9 is tail so again I have to go down so I go down by so from 0, I will have to go down by 1 so I will come to -1. So this will be your M9 and if suppose M10 omega 10 is head then it will again go up to 0 at the 10th place because you will again add 1 so it will become your M10. So what you see that the symmetric random walk is providing me some zigzag looking curve which might tempt you to think that possibly these 2 have some relationships. They are they do have some relationships and we will talk about that slightly down the talk. But let me tell you some more properties of this symmetric random walk M k. So here is my stochastic process and this stochastic process is called the symmetric random walk. Of course we are not mentioning but underlying we are always taking some probability space and all of those things. So now we will these random this particular random process of stochastic process has independent increments. What do I mean by the fact that they have independent increments? What I mean is the following. So if you have you take certain numbers sometime say some K m then you have the following. You have M k1 that is once you consider non-overlapping intervals then this difference is independent because they depend on independent coin tosses because coin tosses are independent when the coin tossed at the second level really does not the second outcome does not really depend on the first outcome right when you do a repeated coin toss sorry M k2 - M k1,…, M k m- M k m-1. So these random variables are independent. All of these random variables these form a set of independent random variables. So that is once this happens this is when we say that it has independent increments and this actually has independent increment. These are independent because their difference which really does not depend on the coin tosses here does not depend on the coin tosses here and here and so you have independent increments. So this change that you see here does not depend on the change that you see in this interval or the change that you see in this interval right. So you can still observe that it is like a drunkard walk so drunkard walks like this goes down goes up. In George Gamow’s famous book One, Two, Three Infinity this has been described in a very very nice way. How do you, see here, my success probability this occurs with probability half and this also occurs with probability half so if you observe that exponential of X j sorry expectation of X j is 0 because this is one into half plus minus one into half. Variance of X j so what is variance of X j exponential X minus X j whole square which is 0 so it is 1 into half plus minus 1 minus 0 whole square plus 1 into half which is 1. Once you have this information this is true for all j. It is immediate that exponential M of k i plus 1 minus M of k i is 0 and the variance of M of k i plus 1 minus M of k i is equal to I leave it to you to calculate these stuffs. Our second property about this random walk is to show that this is also a Martingale. You see Martingale thing comes up. So symmetric random walk is a discrete Martingale. So you can easily prove that it is a Martingale. So you take any k strictly less than l and look at the expectation of M l conditioned on the filtration, the Sigma-algebra F k which is the part of the filtration okay. So you can write this as  M l minus M k plus M k. So these can be summed up just like expectation can be some conditional expectation this random variable can be decomposed into 2 parts which you can actually prove which will be a part of your exercise but we are just using this fact here so, anyway I should rub the board a bit. Now let us look at the first part. Since l is strictly bigger than k this increment M l minus M k is independent of F k. F k does not have the information of anything which is beyond the time k. So here by one of our rules for conditional expectation this is nothing but M l minus M k and here at time k everything about M k is known. So F k contains all information about M k. So the first law was taking out what is known, I can write this M k as M k dot 1 where 1 is the constant random variable 1. So whatever be the scenario it will just give you the value 1. So I can write this as M k so I will write this as M k dot 1 so I can take out what is known 1 dot F k. Of course, 1 is a constant random variable. It does not really depend on is independent of F k so it will be E of 1 which is a constant which will be just 1. So everything will be 1 so the sum of the probabilities will sum up to 1. So the expectation will be just the number. So this again is 0 which we already know plus M k into 1 which is M k and so this shows that M l is a this symmetric random walk this thing forms a discrete Martingale. Of course, F k is M k has to be adapted to this filtration that is the basic definition of Martingale. There is another notion which crops up in the study of these sort of processes is called the quadratic variation. So you essentially look at path by path. You look at how much the random variable values are varying between one end of the path to other end of the path that is between k1 and k2 say how much it is varying but do not take just the sum of those variations they might just be 0 so you have would not get any information but take the square of the variation. It is like a mean square error type thing so we again take here and introduce the notion of a quadratic variation. So the quadratic variation is expressed in the following way. M, M k is defined as summation j equal to 1 to k, M j minus M j minus 1 whole square is equal to and this if you look M j minus M j minus 1 whole square this value is always 1. If you sum them up what will be left here, X j would be left here, the X j. If you take the difference between M j and M j minus 1 you will have the value X j left. X j is either plus 1 or minus 1 so the squaring will always give you 1. So this expression of the square errors basically or the square changes around every path of a given sample I can take the changes but whatever be the path independent of the path it turns out to be k. If you do up to the kth level it turns out to be the k independent of the path that you have taken which is very very interesting. It does not happen for suppose you want to compute the variance  so M, M k is actually variance of M of k think about it how it is possible. But you see to compute this I really do not need to bother about the path but to take variance of M k we are essentially averaging over all the paths. So this is a difference. Now how do I can I do something with this process. Can I increase the jiggling of this process a bit this symmetric random walk a bit and generate some sort of an approximation of a Brownian motion. Generate this sort of zigzagging that we had just seen in the beginning when I had drawn the picture of the stock price that this sort of zigzagging can we generate this sort of zigzagging this sort of zigzagging can be generated by using the symmetric random walk and that leads to what is called a scaled symmetric random walk. We will not go too much of details into it because that might you know take you off track and you might feel a little bit of discomfort for those who are not so very comfortable with very complicated analysis. So what we are going to now show by this scaled random walk is that  what we are going to show by scaled random walk is that we can construct an nth level approximation for the Brownian motion. Let us construct an nth level approximation. So if you are zigzagging by say +1 and -1, I might zigzag by 1 by 10th and minus 1 by 10th. So I will decrease my zigzagging steps but increases my time size right so we construct the scaled symmetric random walk which is the nth level approximation of a Brownian motion. So all these are stochastic processes so this is a discrete stochastic process from which I am trying to go to a continuous stochastic process. I define it like this. You see if I do not have nt to be an integer I cannot define this. So here my t is a t say t between t starts from 0 and say it is up to t or even t goes to infinity so basically for me here this t is just greater than equal to 0. So using the discrete thing I am trying to construct a continuous stochastic process but I have to be aware that if I really want to use it so at the nth level approximation this m and t this nt has to be integer if I want to actually compute this. Otherwise m is a discrete thing it is computed only at integer points you cannot compute it at non integer points. So what happens if it is not computed, if nt does not turn out to be an integer? So basically what you are considering for n very large at various time points nt would be an integer and you are actually computing out of nt. So if nt is not an integer take the t for which is not an integer then take some u and take some s which is nearest to t such that ns and nu. These are integers and then compute the value of Wnu and Wns and then make an interpolation linear interpolation to approximate the value of Wnt and that is how you can actually do you can generate it in a machine by taking a sample so you can take a sample of say so you can do the coin tossing 400 times with one by tenth  you can toss the coin 400 times with probability of half of going you go one by tenth if it is h and you go minus one by tenth if it is tail. So you decrease your movement so you actually increase the zigzag by decreasing the movement and at every time you have to observe that your Mnt nt has to be an integer. Once you do that you will find all the properties that you had for here is in here provided that this M n into t is an integer. So you first do it only for n into t is a integer. Whatever is left you do the interpolation and you will see you will start getting a zigzagging curve much zigzagged than the symmetric random walk itself. Actually it can be shown that as n tends to infinity as n tends to infinity this W nt converges this random variable converges almost surely sorry not almost surely I made a mistake converges in distribution rather converges in distribution. Okay these are terms which I have not mentioned. Just forget them for a while, converges. In some sense W nt as n becomes infinity. This this stochastic processes gets changed into what is called a Brownian motion. So this is what we are going to talk about in the next class. So tomorrow we are going to study the properties of Brownian motion for the next 2 classes. So tomorrow’s class would be the last for the second week of the course. In the third week we continue our discussion on Brownian motion and then go to understand stochastic integrals or Ito integrals and doing Ito calculus which is the foundation of any financial mathematics that you do. Thank you very much."
4,J_uOVllsCVg,Visualising Brownian Motion - Christmas Lectures with Philip Morrison,The Royal Institution,brownian motion,it is worthwhile looking at what we call the Brownian motion I hope you've heard of this Robert Brown was a botanist in London here in London about who lived about a hundred and forty years ago fifty and he found that if he put small grains of pollen and looked at them with his microscope put them in a suspension in water and looked at the with his microscope he often saw them as often he looked carefully dancing forever whether they were even if they were dead they appeared to dance he found it first was because they were living and then people learned that you could do it with powdered sand anything whatever dances incessantly if we look if it is small enough and look at under the microscope I think if you'll watch bill put the microscope on a sample which contains a fine suspension of red powdered pigment in the suspension of water and the microscope can magnify it up and when it is adjusted of magnification about six to eight hundred times you will see a new lights down I think please you will see on the screen the InFocus moving particles you notice how they dance forever it's worth watching it's a beautiful sight and this has nothing whatever to do with their life or their nature any particles sufficiently small placed in the fluid or in a gas where they're free to move will show this motion if only the system is that the temperature of the room you can't get rid this motion no matter what you do we'll talk about that the last lecture quite a lot notice how it goes in a random way now to give some feeling what's going on we have a model here in the model which you will see projected on the screen we have a set of mock molecules no I think when what lights down please mock molecules which are simply small steel ball bearings 64th of an inch across like the Fineman motor magnified up here and caused to move by a magnetic field which is whirling around causing the mover in a somewhat random way notice they're not precisely random eights tend to stick together just as you expect and they fly in all directions at their impurity like a big piece of pink pigment which will show you presently just a piece of paper and it is sometimes hit on one side sometimes on the other and since the number of molecules that hit it is random why of course sometimes there's a unusual number on the left and not so many on the right which case it moves to the right and so it goes it does then a random dance and that's exactly what is happening in the real Brownian motion which we look at again in the real Brownian motion you cannot see the molecules all you can see are the large impurities moving about as the molecules you regularly press them in one direction another because the molecule scores are in constant motion and the Brownian motion is the reflection of molecular motion by things that are large enough to be seen in the microscope even a brick would show Brownian motion but the motion is so small that we can't detect it only in small particles does the scaling allow its detection you
5,FDkLXY3qMAs,How to Demonstrate Diffusion with Hot and Cold Water (Brownian Motion),STEM Little Explorers,brownian motion,"How to Demonstrate Diffusion (Brownian Motion) with Hot and Cold Water You will need: Hot Water, Cold Water, Food Color(s). Prepare 2 glasses of water. One with hot (almost boiling) water and one with cold (regular water from the pipe). Add one or two drops of food color in each glass. You can use the same color, we used 2 for better differentiation. Watch how the color spreads in each glass. Color spreads much faster in Hot water. That process is called the Diffusion and it’s explained by Brownian motion. Particles in hot water move faster and collide more often. That’s why color spreads much faster in hot water. Thanks for watching. If you liked the video, give us a like, and subscribe."
6,UOifsFqy9gE,Brownian Motion &amp; Particle Diffusion,METPHAST Program,brownian motion,"Now we will consider Brownian motion, which  leads to diffusion. So far we have been discussing large particles,  like the green 10 micrometer particle shown on  the right hand side of the slide.  Very different forces are important for small  particles that approach the size of gas  molecules,  like the red 5 nanometer particle shown in the  slide. These particles randomly jitter because of the  bombardment of gas molecules. This movement is called Brownian motion and is  important for particles smaller than about 100  nanometers. Brownian motion leads to diffusion, which is the  net movement of particles away from where they  started. Brownian motion is characterized by the  diffusion coefficient, capital D. Brownian motion is characterized by the  diffusion coefficient, capital D. Shown in the equation in the yellow box, the  diffusion coefficient is directly proportional  to the fluid temperature and inversely  proportional to particle diameter So, if the particle temperature increases, gas molecules move faster, and the diffusion coefficient becomes larger,  and the particle will jitter more. Unlike other forces that we have seen so far,  Brownian motion is inversely proportional to  particle diameter. Thus, this equation tells us that smaller  particles will jitter more due to Brownian motion  than larger ones. Brownian motion causes particles to be  displaced.  Consider for example, if we line up a bunch of  particles at time zero and then allowed them to  randomly jitter.  After some time, these particles become  displaced away from the center, randomly  moving in any direction.  The net displacement can be expressed as the  root mean square displacement,  which is simply the square root of 2 times the  diffusion coefficient times time Shown in the table at the lower right, a small  particle, like a 5 nanometer particle,  will have a large diffusion coefficient, and  therefore a large displacement due to diffusion,  whereas a larger particle, say 300 nanometers,  will have negligible displacement. If we look at this equation, the more time that  we give diffusion, the more displacement we will  have.  To get a better feeling for how particle size  dictates what forces are important,  let’s compare how far a silica particle moves in 1  minute due to Brownian motion and gravity  settling. Again, I show particle diameter in micrometers  and in nanometers in the first two columns.  Then I provide displacement in one minute due  to Brownian motion in Column 3, and that due to  gravity settling in Column 4. Finally, in the rightmost column, I show the ratio  of these displacements that due to Brownian  motion divided by that due to gravity settling.  The force of gravity dominates for particles larger  than 1 micrometer,  whereas the Brownian motion dominates for  particles smaller than 100 nanometers. For a 10 nanometer sized particle, Brownian motion causes 424 times more displacement than gravity.  However, the distance moved in one minute is still very small – 0.002 meters or 2 millimeters. To put things in further perspective, we need to  change the scale of things that we are  considering.  So here, for this plot, on the y-axis, I show the  distance the particle is displaced in 1 minute,  but instead of showing this data in meters,  I show it in micrometers. The x-axis is particle  diameter that we are familiar with.  For perspective, I add that the mean diameter of  a human alveolus is 200 micrometers.  Again we can see that, for particles smaller than  100 nanometers, diffusion dominates over gravity  settling.  These particles, if allowed to stay in the alveolar  region for one minute,  will likely be displaced a sufficient distance to  hit the wall of the human alveolus.  Diffusion can be used to remove small particles  by passing a particle-laden airstream through a  screen.  Brownian motion causes the smallest particles,  say with a diameter of 10 nanometers, to jitter  more than medium-sized particles,  say 100 nanometers sized particles.  The smallest particles, therefore, have a higher  probability of hitting and collecting on the  screen, having a high collection efficiency.  In contrast, the medium-sized particles tend to  follow the airflow, pass through the screen with  low collection efficiency.  In my laboratory, we have used a combination of  inertial devices and diffusion screens to develop  what we call the personal nanoparticle  respiratory deposition sampler, or NRD sampler. The motivation for this work was to measure  nanoparticle exposures separately from larger  particles in a workplace,  because sometimes nanoparticles have more  biological activity than other airborne particles,  even if they are made from the same material.  In this device, particles enter a respirable  cyclone, which removes the largest dust,  nominally that larger than 4 micrometers,  and may cause downstream components to fail. An impactor then removes particles larger than  300 nanometers, leaving only the smallest  particles airborne. Then a series of diffusion screens collect  nanoparticles with an efficiency that mimics  deposition in the human respiratory system.  These nanoparticles can then be analyzed  separately from other airborne particles.  The entire sampler can be worn on the lapel and  works with traditional belt-mounted air sampling  pumps, and analysis can be done by traditional  analytical chemistry methods. "
7,qsFzIv3PHz8,23. Liquids: Brownian Motion and Forces in Liquids,MIT OpenCourseWare,brownian motion,"The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation or view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. PROFESSOR: OK, I was trying to look at your face and see whether you all hate me or not. And I said I was going to send an email yesterday and say, this is the time for your evaluation. And then I realized that if I sent it to you yesterday, I'd probably gather the worst evaluation, right? So I just wanted to remind you, I'm going to send the email. You need to do the evaluation. And sometimes I was-- the other day, I was telling my wife, I said-- because we always listen to this, say, Car Talk. I don't know how many of-- it's a very interesting radio talk, right? So at the end, they always say, we squander an hour with me. And I say, you squander a semester with me. Hopefully-- OK, so we have three more lectures. And this is not going to be a review of the past. We're going to continue pushing and see how much we can stuff there. What did we talk in the last lecture-- we focused on the p-n junction. And then from p-n junction, solar cell. In fact, it's very [? lateral ?] just to say you got a carrier generation by photons, which goes the opposite for the bias. And then we mentioned the Shockley-Queisser limit, where the key is that the Shockley-Queisser-- in fact, I just had a program manager call for two hours in the morning on the PV project that we have. And so the Shockley-Queisser is assuming there's no other combination other than, really, the recombination. And for photons emitted, say, when the electron calls not at the equilibrium. Therefore, there is a difference in the Fermi level of the electrons and holes. And the photon emitted has a chemical potential, right? The chemical potential is the difference of the [INAUDIBLE] formula was. So I was presenting some of the understanding I had at the end of the last lecture. This is a very interesting thinking from the entropy perspective. And so with that, we pretty much finished, in terms of what I want to do, a parallel treatment, right? If you think about-- we talked about molecules. We talked about electrons. We talked about phonons. And we talk about the photons. And often, we can treat them more or less parallel because they are dilute particles. And they have wave characteristics. And the way that we've been dealing with this is we talked about energy level, that's due to the wave nature and the quantization of energy, due to wave nature of those matters. And then we see eventually-- so at a single interface or model interface, you have in the first-- you have reflection. And that's mathematically-- for your approximate interface, that is zero sickness. You know that is always smaller than the wavelengths, right? So this is what chapter 5 was about. And from there, you could calculate transmission. So those were a description under the wave picture. Then we move on to really the transition from that wave, if the wave-- the coherence is lost. I don't need to consider the phase information of those waves. I just need to consider trajectory of those waves. And that's to say, where it's completed treating at the particle, right? So if you think about quantum mechanics, what Einstein introduced is the granularity of waves, of photons. Photons, electromagnetic waves, are granular waves. So it's a particle and wave duality. And the way that we've been treating it is, OK, we first try this either wave propagation and then eventually, we completely enacted a way we treat them as a particle. We don't carry the phase anymore, right? So there, this is from the transport perspective. And then we went to the Boersma equation. And using the Boersma equation, we hopefully have seen all the diffusion equations or drift-diffusion equations in bulk materials. And then when you have boundaries where the boundary creates some scattering of those particles, just like when you go play pool. And then your particle, your ball, hits the boundary-- again, reflection, right? For most of those [? transport ?] potential, there's a diffuse reflection that create additional impetus for the carrier flow. And then chapter 8 was trying to wrap the idea that microscopically, when you think about energy conversion, it's really the transformation of one type of energy carrier energy into another type of energy. So that's the interaction, the scatter and the absorption, the excitation of energy carrier. But at the same time, you have the loss. You have the transport. So you want to design a good heat engine. Your thermodynamics has to be right. That scatter-- and we have energy conservation. We have momentum conservation. You can think about that as the thermodynamics has to be right. And then your transport has to be right. I say, that's the left hand side of the Boersma equation. And I warn you that I couldn't do liquid, right? So if I think about electron, phonon, photons, or waves periodic boundary condition and eigenmode-- and so with that, they dilute particle approximation as violet. And to deal with-- so the next thing is we're going to talk about liquids. And I will spend only very little time on the transport in bulk liquids. And in fact, I think when I look at the literature-- I think we don't really even understand well, transport in bulk liquids. And it becomes much harder because the liquid, as well as an amorphous material-- you go to amorphous silicon, right? You lose that periodicity, right? Crystal is an idea because when you say, give us structure, you only have one arrangement, perfect crystal, purity. But when you say amorphous, where the atom can be anywhere, you've got zillions of arrangement. So that makes the picture much [? harder. ?] And the liquid-- so liquid, in fact, the difference between amorphous material and liquid is very small. And if you think about glass, you would typically think of this as a solid. But the glass, if you look at people starting this say, glassy face, they have radiological properties. They could change, all right? And so first, I gave a very brief [INAUDIBLE] for the bulk properties, and how people try to treat it. And then quickly, this field went to computerized, computer simulations. And then I'll discuss more on the interfaces. In fact, that's probably most interesting if you deal with transport-related liquids-- how the liquid interact with solid at interface, including the electrical bubble layers and the solid, solid interaction when we have, say, these interfaces. So that's chapter 9. And we're talking about liquids and the interfaces. And I mentioned, if you look at the-- for liquid, what are the historic approaches, people trying to deal with the liquid? One approach is trying to modify the Boersma equation. Boersma equation is a dilute particle. So when you have a more concentrated, high pressure gas, for example, the particle is a lot longer, very dilute. So you have the approach. You modify Boersma equation. And I'll briefly mention 2-particle distribution-- distribution function, and the corresponding Enskog equation. And then the other approach is really starting with Einstein, is the Brownian Motion. And it eventually develops into the linear response theory. So those were some of the directions. And eventually, this one didn't pan out. It's not very fruitful, Boersma equation. They tried to modify. And so most of the studies now is based on computer simulation and linear response theory. So let's really give a very brief picture of bulk liquids. And one of the variables of the function we use often to characterize liquid is the radial distribution function, which actually can be measured using tools like a neutron scattering tool. And the definition is, OK, I have-- so this is trying to measure, what's the order of the atoms? If I take any of the atom out of the center, how are the surrounding atoms distributed around this atom? And so the radial distribution function is 4 pi. Really, 4 pi ask r-squared-- the r gives you the volume around the r. And this n is the average density of the atoms. And this is the radial distribution. So basically, if you look in this radius r, from the atom, and look at the thickness of dr-- so how many atoms do I have in this small shell of volume? So this is the definition for the radial distribution function, so the number of atoms in r and r plus dr. And if you think about the difference between liquid and gas and the crystals-- typically the radial distribution function. So crystal, if I look at the atom, this is the center. The next atom is some distance away, the next layer. And then the next layer is periodic. So you continue. That's the crystal periodic arrangement. And so if this is a g as a function of r and r-- and if you look at the gas, the gas is pretty much like a uniform distribution. And so there is really no structure in the distribution function. And then you look at the liquid. Liquid is to say, if I take an atom, immediately surrounding there because of the mutual influence of the atoms, there is a little bit of structure. And away from it, there's no correlation because the atoms are moving pretty randomly. So the way I can-- the typical distribution function of this is dying off after a few layers of atoms surrounding this vessel, any of the [? space in the ?] atom. OK, so what's the use, if you use the radial distribution function? For example, I can calculate, if I know the potential interaction between two atoms. So if I know the potential interaction between two atoms, then I can calculate using the radial distribution function, what's the total potential energy in the system? Is it 0 to infinite integration, 4 pi r-squared? And this is a potential interaction between two atoms and grdr. And if you go back to the thermodynamics-- in chapter 4, we consider the different partition function, micro-canonical system, canonical system, grand canonical system. If you write down the potential energy and you have kinetic energy. You have potential energy. You can actually write down the distribution functions. And from the distribution function, you can calculate the corresponding thermodynamic potential. A canonical system, it's the freedom-- free energy there. And micro-canonical is entropy. So once you have this thermodynamic function, you can derive all the thermodynamic properties of the system, like the equation of states, right? So one interesting case was the equation of states. So for example, if you say Van der Waals-- this is the famous Van der Waals potential. If we take a Van der Waals potential, phi-r-- the small phi-r, is 4-epsilon and sigma, or r, 12th power, minus sigma over r, sixth power, one rest potential. And then let's suppose that I have-- this the radial distribution function as a step function. the radial distribution step is zero. So it's basically-- here, I'm drawing this way. But this step is just here. This is my d. So within 0 to d, this distribution function is 0. So this is an r less than d, right? You can't have atoms together and closer than d because that's the territory of the specific atom. And when r is larger than d-- let's say this is a 1. So we lost the structure completely once this is getting out of this region. So if you take these two functions, you plug it in. And what you find out is that your phi-n is-- so the total potential of the system is an squared over v, the volume. And using this potential energy and kinetic energy, you go reconstruct the partition function. And from partition function, you get a equation of states. And equation of states-- the equation of states that you have is p equals NkBT. And wave must be n, minus a squared over v squared. And the B is the volume for the individual molecule-- one molecule. So this is the equation of states that's slightly different from the ideal gas law. Ideal gas is p equals nrt, right? And this is Van der Waals equation of states. It comes from the Van der Waals potential and Van der Waals equation of states. And it has a very important historical importance. And in fact, if you go to check, probably the Nobel Prize-- the first one in physics was in, I think it was the X-ray. And the first one in chemistry probably was one Van der Waals, OK? And why? Because if you look at the ideal gas law, it's p times [INAUDIBLE] equals nrt, right? But the Van der Waals equation of states is actually giving you the liquid. So part of the equation of states-- so this is for the Van der Waals gas, it looks like this-- Van der Waals equation of states. And it turns out when you take a horizontal line, you create this area. That's where the horizontal line should be. And this is the liquid. And this is the gas. And the in between-- so for different temperatures, you plot it in between. You have the vapor dome, right? So you look at the steam characteristics. In this region, you have mixtures of liquid and steam. And this is the steam region, liquid region. And it turns out, this one-- in between, let's say this is a, b, c, d. And the b to c, this region is impossible. And in this region, you don't have a homogeneous state. You decompose. So you've got a mixture. You've got another one phase. You get water and steam. And this is the sub-cool you can potentially have, super heat. And in between, some of [INAUDIBLE] is absolutely unstable. So you've got mixtures. And of course, normally, we always get those mixtures in the whole from a to d region. So the importance of the Van der Waals equation really gives you characteristics from liquid to the vapor phase. Historically, very important. So that's the thermodynamics part. And from the kinetics part-- so that's a transport, right? So if you think about the Boersma equation, the assumption we have in the Boersma equation is the molecular kills, right? The distribution function at the end that we say we can use one particle in the system, one particle distribution function to represent the distribution of all particles. So if I write down a 2-particle distribution function. So I type T. One particle has a position, a momentum, rp. And second particle has a position and momentum, r2p2. That's the 2-particle distribution. And the Boersma equation is based on the molecular chaos assumption, which means this is independent of each other-- The trp times the tr2p2. That's a molecular kinetic assumption. And because of this, the n particle is just a product of all those distribution functions to the n-th power. And they correct it. So at the beginning, there was effort until '60s, OK? People were trying to do correction to this molecular chaos assumption. And one of these is due to Enskog. And Enskog is still pretty much like a hot sphere. And TRP and r2 p2 equals ftrp-- ftr2-- p2. There is a function-- add a function to prevent, for example, the two molecules or two atoms that occupy the same location at the same time. So you can use that hot sphere. So here is the function that represents the distance of the two molecules. And with this power distribution function, you'll go back to the derivation. You start with the [INAUDIBLE] equation. And when you simplify to 2-particle and you look at your scattering term, you derive a set of equations for f, as well as for g. What I want to say, I didn't write. In fact, I didn't even write in the book. It's very complicated equations. But there were effort-- and in fact, there are some solutions to the Enskog equation. But it was found that the Enskog equation, you can do a little bit denser fluids, not liquid. Liquid is very dens. And you can do a denser gas. But the range cannot be extended very far. So because the equation gets very complicated and this route of extending the Boersma equation was not successful. It was pretty much abandoned after 1960's. So the other direction came from Einstein. And Einstein did a Brownian motion. And that was his PhD thesis. He wrote this and went to the Patent Office. And they published all his papers in 1905, the relativity, photoelectric effect, and the Brownian motion. And so these were by year publications. So at the time, he didn't even there were Brownian experiment. But he knew a few facts. And he knew that if you have-- so his purpose was trying to determine what's the size of molecules, OK? And he knows that when you have-- so he was doing more deduction, thinking experiment. Say, OK, if you have particles, big molecules, you are solvent. You put the milk in water. And the one thing he knew was that there is an ideal gas law type for those solute molecules in the solvent. And this is the osmotic pressure. He knew osmotic pressure. And so the osmotic pressure, p, is the same as ideal gas, nrt. a is the number density of those molecules in the air, the solute molecule in the solvent. So that's one thing he knew. And the second thing he knew was fluid mechanics, OK? And Einstein knew that when you have a particle, and in fluid flow, you have-- of course, this is a very small particle. And the Stokes drag. When a particle moves in the liquid, there's drag flow-- drag effect. So the drag force-- does anybody remember the drag force? AUDIENCE: 6 pi mu D. PROFESSOR: OK, 6 pi mu de D. Well, is it D or R? OK, I have 3 pi-- AUDIENCE: It's mu R. PROFESSOR: Right, so it should be R, right? OK. R times velocity, Stokes's formula. And he uses this to construct the-- what's the diffusion mass flux? So you can do this by saying, OK, I have osmotic pressure. If I have a concentration gradient, I have a pressure gradient. So a is the concentration. So if, let's say, in the x direction, there's a concentration gradient. You take a control volume. And you do your pressure. So px minus px plus dx. And I should say, this pressure at the steady state [? through ?] the balance of the drag force on the particle. Due to the osmotic pressure, the particles are moving. And the resistance on this particle is due to the Stokes flow, drag force. So what you have here is times-- let's say here. This is a pressure times the cross section. Let's say here is your cross section we're considering-- and minus 3 pi mu D. I don't use R. And u times the number of particles in this volume. That gives me steady state, pressure-driven force, and resistance due to the flow. And if you write it into differential form, what you have-- because AC times, eventually, dx, gives me volume. [? dvA, ?] [? dN ?] and [? dA ?] gives me another N. So I will have-- what you get out of this is n times u equals minus one third, 3 D mu, dp, dx. And dp/dx, when you convert it into using the osmotic pressure relation, we have kBT and 3 pi D mu and dn/dx. So this is the flux. If you look at this, number density times velocity gives you the flux meter squared, the number of particles per meter square. So what we have here, essentially, if you think about Fick's law, this is your j flux equals minus a, dn/dx. That's the diffusivity. And here, the diffusivity is related to the viscosity diameter, right? So from here, you can say the diffusivity is a kBT and a 3 pi D mu. So from here, Einstein says you can do an experiment. Your drop of milk-- you measure diffusivity. Time it, and you can visibly see it. You know the viscosity. This the viscosity of the liquid. You know that. You know that. You know what's the diameter of the molecule. So it's very simple, right? And so that's why this is called the Einstein relation. Recall when we talked about semiconductors, the semiconductor has a diffusivity. And the mobility has a relation. And here is diffusivity viscosity. Viscosity is also-- so in the term, mobility is, like, an inverse mobility. This is a diffusion process, right? So diffusion is due to fluctuation. Viscosity is a sort of friction dissipation. So this is one example of the more generalized fluctuation dissipation theory. Here we have fluctuation. Here we have dissipation All right, OK, so that was Einstein treatment. And in fact, Einstein later on solved the other way. So if you do nano fluids, you go to read the Einstein paper, he actually saw, this is one way to do this. And he'd say, OK, you can also add a nanopart-- I called it nanoparticle-- those molecules. And you measure viscosity increase. So what's the viscosity increase to the base fluid viscosity? And from there, he had another way to do the same problem. So for that problem, he actually has to solve-- he actually solved the viscosity flow problem around particles. So you can say he's a fluid mechanician. We didn't go to the other research, fluid mechanics. OK, so that was the starting point. There was a very small book on the Einstein work in this area, on the Brownian motion-- and very cheap, $10. You should go to get take a look at it. And so from here, there was the generalization. So Einstein had said the lesser generalization is due to Langevin equation. And the Langevin equation is a stochastic question. Just say, OK, is F=ma? But the driving force is due to random thermal fluctuation. So if you write the-- if you have, say, a particle in the liquid and surrounding fluids, give a kick, random. And then this says you have, then, the acceleration, ma, the d velocity, dt. And the force acting on the molecule or atom or particle, when you start moving, you always have a drag force. So the drag force is always there. And drag force is proportional to velocity. OK, you can write into normalized to mass. But say it's proportional to velocity. So you can do a vector-- put a vector. So there is always drag force. And then you have random kicking force, random force, the fluctuating. So that's the random driving force. Here is random. And there's some basic relation because there's a random force. So the average is 0-- itself is 0. And this random force is not related to r. So if you do your time average, they are also 0. But the driving force itself, of course, is related to temperature. So if you say here is the different time, r-- at the time, s. And the typical Langevin equation assumes this is instantaneous. So there is no memory. And here, what we have is 2 m eta kBT, and delta, t. Delta t is just to say instantaneous. And this random fluctuation is related to temperature and also related to how large is the dissipation here. OK, so this is the Langevin equation. And solving this little Langevin equation-- because this is random. So actually it could be pretty-- you go through rigorous math. There are many different ways to solve this random. You can do a spectral analysis, for example. But in the book, I'm not going to present going through every step, we have a very non-rigorous way, just to say, I multiply both sides because this one du/dt, can be written as d/dt, dr/dt. So if I multiply both sides by r and you go take the time average, this term actually drops out. So you get a regular equation you can solve-- an ordinary differential equation, so you can solve for the radius-- the radius of the particle from t equals 0. So here, I'm going to give you the results. So if you do the radius of this, r square, this is where, if you put a particle here, after some time, where it's going to be. And this is the random walk. And the radius is 6 KBT, m eta, and then t minus 1 over eta, and plus eta exponential minus eta t. So this is the solution for the distance from the origin [? built ?] to the random walk of this particle. And you notice, there is this long time-- this term drops out, right? So the diffusion, the distance-- because this is related to diffusivity. So the distance will be really, diffusivity times the time square root. That's the order of magnitude of the diffusion is. This is when you saw the Fourier law of heat conduction, you know the diffusion of heat is diffusivity times time, square root. So that's the long time behavior of the Brownian motion. So the heat conduction, all this diffusion, is a random walk process. And recently, if you check the literature, there are actually a lot of people still doing the Brownian motion experiment. And some people say, we did the experiment. We say the initial term also. That's the translating at the start of the kicking. So one interesting comment I have here is if you look at the Brownian motion, look at the velocity here, forget about this. You see the velocity will be exponential decay because this is the velocity. This is velocity. If you solve velocity, this is exponential decay after. It's getting quickened, right? So all this relation comes from-- related to the exponential decay. But it turns out this is wrong. And the reason for this is wrong is in this Langevin equation, there is also-- when your molecules get a kick-- here you use the Stokes theorem-- Stokes drag. But when a particle starts from 0, this is a steady state solution. And when a particle starts from 0, stationary, gets a kick, you get a transient solution. And that transient term-- what's significant, if you add a transient term into here, there should be additional transient term, the Stokes force. And that transient term is integral. So it depends on the previous time. So this equation actually becomes an integral equation-- differential integral equation. And if you solve this differential integral equation, you don't get the exponential decay for velocity. You get a power law for the velocity. So if you saw, velocity is actually, if you solve this transient, is t-- remember, it's 1.53, three halves. So it's a very slow decay. Exponential and power are very different, right? Exponential is a very fast. Power is slow. So that's the memory, in fact, of the Langevin equation. And I was interested in this because-- so the discovery of this memory effect was by computer. So in 1950 or 1960, when people started doing the computer simulation, molecular symbolism, molecular dynamics, they found this is not the case with velocity, all the correlations. So typically, you calculate. Turns out later on, when we we go to linear response theory, you see that diffusivity is related to velocity autocorrelation. So it's ut u0, dt. So that's a velocity autocorrelation function, right? So you can see, if it's a power decay, you would expect that this is very different. Was Einstein's original relation between diffusivity and mobility wrong or not? It turns out that even though he didn't [? include, ?] even though he has an exponential decay, but the autocorrelation, at the end, the result was the same. So he was lucky. They determined the fluctuation dissipation relations still valid. Even the decay function is very different. And this was later proven. There was a paper later proven mathematically by some integral differential equation that said this is still valid. So I was interested in this problem because for a long period, people are doing this with nanofluids. They added nanofluids in the liquid. They say there's higher cerebral connectivity. And their theories say they're Brownian motion, whether it's a Brownian motion, in fact. And Brownian motion, if you do this exponential decay, it drops very, very rapidly. And you go to do all the automatic things-- about five, six automatic-- too small to actually contribute to heat conduction. Then there are other people at the same time-- we actually found the paper that said, oh, this is a much slower decay. And because there's a power law, and that may be explaining the strong connectivity is not exponential. And then they went further. And they say, OK, it turns out that people prove at least for viscosity and diffusivity, that's a fluid flow problem. It's still valid. So then the question is for heat transfer, for energy, is that valid or not? It's an unanswerable question, OK? Later on, we did an experiment. And we don't think it's a Brownian motion. But mathematically, that's still one thing in my mind, is what is the autocorrelation function for heat and how they decay in a Brownian fluids. And when you consider this time retardation, the memory effect, what people call memory effect because it takes time for the Stokes flow to kick in. OK, so that's all I'm going to talk about for the bulk fluids. And I think that there are actually really a lot of very poor understanding, even on the basics, of transport in liquid. And there is some potential to do good research in this area. And next, what are we moving on is going to talk about the interfaces. So what's important is to understand the potential interaction. And so let's look at the forces and the potentials. And of course, we know force is the gradient of potential. So if I know the potential, I know the force. And what we're looking at is more longer range potential, so due to the charge. We're not looking at the covalent force between that typically connects the atoms to form molecules. So when we look at the longer range potential due to charge, you can always start the most basic. So let's do, of course, the most basic Coulomb force-- Coulomb interaction. We'll have a positive charge, a negative charge. I have this is as a Q1, this as a Q2, and the potential as Q1, Q2, and 4 pi epsilon r. r is the separation between the two. Here is the r. And you can use the basic Coulomb potential to construct all other forces that, due to elect, let's say, this charge or region, due to this Coulomb origin here. And so for example, I want to understand what's the potential between a single charge, Q, and the dipole. A dipole is a positive and negative charge very close to each other. So I'm going to have a dipole here of positive and negative charge. And here is minus Q. Here is a plus Q. And let's say here is A. And the distance of the dipole here is d. And the separation-- the dipole-- this d is much smaller than the radius, the separation between q and the dipole, that's r. r is larger than d. So you could then just sum up all those Coulomb potential. What's my potential here, is the potential is equal to Q-- to this Q or to this Q here. And this is a b. This is a c. So if I write the 4 pi [INAUDIBLE] AB, so to the negative charge, plus this Q to positive charge-- 4 pi epsilon, to AB. So I have a AC. So you just write the distance down. And do your math, using the fact that the-- so, here if I do the AB, for example, is r minus d over 2 cosine theta squared, plus d sine theta, d over 2 squared. So that's my-- the orientation of this dipole. This is a theta. D-- so it's a 1/2 d. That's this distance, times sine theta. That's this one. And then minus-- that's because on this side. And that's the distance, AB. It's just the hypotenuse of the right triangle when I'm writing down. And similarly, you can write AC. And then you use the fact that r is much larger than D. You linearize it. And what you have here-- I have minus Q. Theta is a dipole moment, cosine theta, and 4 pi epsilon r squared. I'll say beta is the dipole moment is the Q times D. So now, this is in my potential originally for a single. You can say for two point charge, I have the potential is 1 over r. So the force is 1 over r squared. Now if I look at the point charge in, dipole the potential is over r squared. And the force is over r cubic, right? Because you want to know what are those relations? And as another example, I want to find out, what's the forced interaction between two solid surfaces? Why I'm interested in that? Because I want to say, if I put a particle in liquid, what do they-- what is the attraction force, whether I can keep this fluid stable or not? If they glue onto each other, you have, eventually, sedimentation. How can I make a stable [? column? ?] You need to know those forces. So I have constructed, using the simple Coulomb potential, between-- a point charge and dipole. I can look at the last what I have, when I look at the dipole-dipole. So if you look at two dipoles, due to the Coulomb interaction, because you have-- the dipole has a positive or negative. Each one has a positive and negative. You interacted with the other one. You got the full term summation. And then you add up all those four terms. And you find out that your potential for dipole dipole due to this is r-6, right? When we talk about Van der Waals potential, this is the attractive part. And then when they get very close, you got the repulsive part. Here we're talking about the attractive half, OK? And with this, you can-- so this is a two isolated dipole. Now, with this dipole, you can go construct. If I have a dipole and I have a solid, what's the force? What's the attraction between this dipole and this solid? The solid itself, I'm going to consider not a solid that's made up for-- not a single point charge solid. I say it's neutral. Each atom is neutral. Then I can approximate that atom itself as a dipole. So really, each point that I have dipole, I'm going to sum up the first interaction of this dipole with all the dipoles in the solid. So if you do that-- so here, I have the distance, d. And let's say, here, I have my [INAUDIBLE],, the x. And because of axis symmetry, I can consider any x I do-- I say when I integrate or, say, infinite. If I consider either any x radial direction, so this is like I have a cylindrical coordinate. And I can write the potential interaction between this dipole and the ring here as-- because it says the distance is the sixth power. So the distance here, if I look at this point, and this is the r, here I have D plus x. So I have a D plus x squared, plus r squared, and sixth power. So this is my distance. And then I have the lumbar density of this dipole atoms, and 2 pi rdr-- that's how many I have-- and then times dx. So that's the volume. And so dx-- and then I integrate-- the x is 0 to infinite. This is my origin, 0 to infinite. That's x. R, I zero to infinite. The order is solid. So you do that. What do you get? You do your integration. You get the-- this is a pi n, and a 6 D cubic. So D is the separation between this dipole and the wall-- and the solid. And that's a potential. If I do it once I have the potential, I take the derivative. So the force is a D force power. OK, now if you go to check in the book, I give example because people say, do I have a slip when I have a liquid flow on a solid surface? So I use this. That represents my own opinion. I said there is no slip in the normal condition because I'm just saying, when I have this dipole, what's the bonding force? And then I look at it and say, I have the atoms. And what's the potential barrier on the surface? And the question is whether I have enough shear force to [INAUDIBLE] those potential barriers. So I guess my point is that you can take that. You can criticize it. But the point is, you can develop your own argument. And then you let others shoot it up and say, where is wrong here? And of course, if you have very large shear, you may have it. But in a practical situation, I don't think there is a [? slate ?] between liquid and solid surface. OK, so this is one dipole to a all solid. And now I can do the same if I have two pieces of solid to a parallel plate. So I have two parallel plates separated by D. And if both sides are dipoles-- and again, now you already integrated one side. You just integrated this other side also. In that case, what you have is a phi equals minus A 12 pi D squared. And this A is pi squared c, and n 1 times n 2. The n 1, n 2 are the number densities on both sides. And this A is called the Hamaker constant. How many of you have heard of Hamaker constant? That's where it comes from. And so now, this is the potential. So what's the forced interaction between two parallel plates? Van der Waals force, that's D squared-- D cubed, right? For two atoms, you do D 6, potential D 7 force. And for two parallel surfaces, it's D cubic. You can do spheres also-- different geometry. And in fact, you read the books, people have done all those. So with a different surface, there is a corresponding-- that integration gives you different Hamaker constant. And by the way, this was considered-- this a classic. There's nothing really complicated. You can do that. You go back and you redo it yourself. But that was in-- I think it was in 1940's or 1950's. The same problem was to put a different spin. And this was a suggestion by Max Born to Casimir-- Casimir again, right? So we said Casimir did this size effect on thermal conductivity. And Max Born suggests to Kashmir, said, this Van der Waals force can be understood also as a zero-point energy. So then Casimir went back. What he did is, OK, if you have-- this is the other way to look at this force. And in this case, there's no longer electrostatic. Here is the electrostatic. It's Coulomb force, right? But this other way to understand it is like the mode. The energy of electromagnetic waves stay in this gap, right? And so this is the mode. And there are many other modes. If you think about it, it's the perfect reflecting surfaces. As you move closer and closer, there are more modes that are excluded. So the energy in this cavity is smaller. So if you know the energy, again, you take a derivative of this energy. You get the force. And this mode is zero-point because one half hu, that's the energy. That's zero-point energy in the cavity. And it's the other interpretation for the Van der Waals force. So let's now give you a quantum picture. It's important because now, if you look at the lots of work on Casimir force. But this one, of course, is electrostatic. So this picture is electrostatic. So the mode is more getting into the dynamics, right? So later on, there are further developments by Lifshitz. The [INAUDIBLE] Lifshitz, the Lifshitz book. And he developed a theory based on just the electromagnetic wave. You really calculate using dielectric functions of median 1, 2, 3. So what we have here is the electrostatic limit. But if you do electrodynamics, you can have a generalized theory. And that generalized theory, it turns out, depends on the dielectric constant of the epsilon 2. Here, we are talking about Van der Waals is attractive. This tool actually, if you have another media, right media in between, you can actually have a repulsive. The two surfaces can actually repel each other. So some people are trying to develop that in the MIT campus-- a lot of faculty, several faculty, Steve Johnson and I think Carter-- [INAUDIBLE] Carter, and several people are working on this. So the idea is, can you develop a surface if there's no friction-- if you can repel those self-repelling. OK, so with this, we have talked about the attractive forces, right? And like I said, if I want to look at-- I put a particle in fluids, and if there are only attractive forces, they will agglomerate and sediment, right? And you need a repulsive force to maintain them, if you want to have equilibrium. You can keep this a certain distance. So in the next lecture, we're talking about that. But I want to go back to the solar cell. I want to show you a few slides on solar cell. I didn't have time last lecture. OK, so I didn't show any of these graphs last time. We talk about basic principles. So here is Shockley-Queisser limit calculation for the maximum efficiency of a solar cell. And it depends on the band gap of the material. So here, you can see this is the concentration. If there's no active concentration, you get the-- this is about 1.4. That's the peak. And the peak efficiency is about 23, 20. That depends on what kind of spectrum you take. And the original Shockley is about 28. And this is about 31, 32. So this was a paper by [INAUDIBLE].. So this is about a gallium arsenide band gap. 1.1, this here, that's silicone. So silicone and gallium arsenide are in the good band gap range. And here is the efficiency. If you concentrate this 1,000 times, by concentration, you generate more photons. If you look at it, then you have larger open circuit voltage, and also higher short circuit current. So you get the higher efficiency. And that's a single junction. And here was some historical-- it's an old one, you can see. And the silicone-- the best crystalline silicon, that's this line here. And I actually with the [INAUDIBLE],, the group before, they say they have about 26% efficiency. And so actually, this is a single junction cell. Single junction cell is the best with Shockley-Queisser. I'd say about 30, 31%. So that's actually getting pretty close. And what's interesting here is the multi-junction cell. The multi-junction cell now is about 41, 42% efficiency-- 43? Yeah. AUDIENCE: [INAUDIBLE] 43. PROFESSOR: Huh? AUDIENCE: [INAUDIBLE] 43. PROFESSOR: OK. 43, they split-- that's by wavelength, split into different cells. That's another one. AUDIENCE: One. PROFESSOR: It's one? OK. But see, I think here, this one is the cad telluride. That's the first solar. It's a lower efficiency. It's a direct gap solar cell. And the first solar, cadmium telluride, you almost get the worst in the world. But they are most profitable company. Because cadmium is a poison. It's toxic, environmentally. And you go to Japan, they had an environmental disaster in the 60s. They never touch cadmium. But first solar, they use a thin film. Their film is a few microns because the optical absorption is a good direct gap. And they are selling about 11%-- 10% to 11% efficiency. The silicon cell is [INAUDIBLE] anywhere. This is lab efficient. That's the best efficiency. Silicon cell is selling anywhere between 15% and 18% or 20% efficiency. So at the end, there is a cost because they are the most profitable because the silicon is about-- a few years ago, $3. So now it's-- this cost curve is dropping very fast. And a lot of work is done on the polymer solar cell. And you see the history there. And this should be the diesel. It's an open circle. That's the diesel. And that's what-- it should be around 11% [INAUDIBLE].. But see, eventually, which one is going to win? Which one goes first to get the grid parity? Grid parity means it can compete with coals and natural gas. It's very cost sensitive. Multi-junction cells is trying to use different spectrum of the wavelengths. And it's actually really quite ingenious, in the sense you have a wider gap semiconductor on top. So the red light doesn't get absorbed, go through [INAUDIBLE] on the bottom. But you have to connect them correctly. Each cell has to generate-- because you're not putting the cell in series, right? The top cell generates a certain current that goes to the next cell. So the current has to match. And also, typically when people connect, they do quantum tunneling-- tunnel junction to connect them. So if you make an infinite junction, practically, people [INAUDIBLE] junctions because when you grow different materials, they become very crabby. And once mature becomes crabby, it doesn't work. Recombination is too fast. But theoretically, if you do infinite junction, you can get around 86% efficiency. And recombination, we already mentioned. So this is where the silicon is very good, abundant. This optimal absorption, that's really not good. That's the problem. See, [INAUDIBLE] the cost. So you need the thicker one to get the absorption up. And that's related to materials because you have to use very pure materials. So this is the single crystalline and polycrystalline. If you go out, you look at this, that's your-- you pretend you're an expert, whether you have a polycrystalline. Look at this-- colorful. That's poly. That looks like a more monocrystalline. And then people are trying to do thin film, for example, amorphous silicone. With amorphous silicone, the problem is the mobility. Charge does not travel very well. So even though you can use a 500 nanometer amorphous silicon, it's still too thick for electron holes. So you want to make it even thinner. And once you get a very thin, the optical absorption is also a problem. And here, people have actually tried to make-- you can see here. You have amorphous silicon. That's the widest band gap. And then you have microcrystalline silicon, or you can have silicon germanium with a different band gap, so that you can multi-junction cells. This is a polymer. Polymer, unlike the typical pin junction, where you got a potential-- in fact, the potential is not that important. Just by diffusion you find the concentration gradient. And the polymer problem is the molecular chain. You excite the electron hole. The problem is that the electron hole, they're bound to each other. So they actually have a lower energy. That's acetone. And what you want is to extract them out. The electron goes one side, hole goes to the other side. But acetone, if they bind to each other, eventually they die. They release heat. You're doomed, right? So first you need to separate the acetone. And then get it onto the polymer. Again, the conductivity is not good. So people are doing this three dimensionally. One is a hole conductor. The other is an electron conductor that's bulk junction solar cells. Even though when I say bulk junction, it means that it's a penetrating junctions, PM, [INAUDIBLE] materials. And also, you have to make it very thin. And Gratzel cell, electrochemical cell-- they use, really, molecules, their dye, as the synthesizer. And it's a monolayer. So they coat them, every nanoparticle, with monolayer, to increase absorption. Again, you get the electron hole, the acetone. And once you get that, because it's a monolayer, so you generate the electron hole. And one goes to the solid. That's the titanium oxide. Titanium oxide is in cosmetics. So it's pretty cheap. And the hole goes to the liquid. So the liquid oxidizes and diffuses through the electrode-- and then reduced. And so this is where, because it's a liquid, it's not very reliable. And the reliability is a big problem. And so people say this could be cheap. But so far, nobody has been able to commercialize them. OK, so that's what people are trying to do. OK, so here is a first gen, silicon-based, thin film-based, whatever solar you can try to get a lower efficiency-- higher efficient, low cost. There's a lot of people working on this. OK, stop here. And just a reminder, I'll send you an email. Now you can vent all your angry."
8,PPl-7_RL0Ko,17. Stochastic Processes II,MIT OpenCourseWare,brownian motion,"The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation, or view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. PROFESSOR: And today it's me, back again. And we'll study continuous types of stochastic processes. So far we were discussing discrete time processes. We studied the basics like variance, expectation, all this stuff-- moments, moment generating function, and some important concepts for Markov chains, and martingales. So I'm sure a lot of you would have forgot about what martingale and Markov chains were, but try to review this before the next few lectures. Because starting next week when we start discussing continuous types of stochastic processes-- not from me. You're not going to hear martingale from me that much. But from people-- say, outside speakers-- they're going to use this martingale concept to do pricing. So I will give you some easy exercises. You will have some problems on martingales. Just refer back to the notes that I had like a month ago, and just review. It won't be difficult problems, but try to make the concept comfortable. OK. And then Peter taught some time series analysis. Time series is just the same as discrete time process. And regression analysis, this was all done on discrete time. That means the underlying space was x_1, x_2, x_3, dot dot dot, x_t. But now we're going to talk about continuous time processes. What are they? They're just a collection of random variables indexed by time. But now the time is a real variable. Here, time was just in integer values. Here, we have real variable. So a stochastic process develops over time, and the time variable is continuous now. It doesn't necessarily mean that the process itself is continuous-- it may as well look like these jumps. It may as well have a lot of jumps like this. It just means that the underlying time variable is continuous. Whereas when it was discrete time, you were only looking at specific observations at some times. I'll draw it here. Discrete time looks more like that. OK. So the first difficulty when you try to understand continuous time stochastic processes when you look at it is, how do you describe the probability distribution? How to describe the probability distribution? So let's go back to discrete time processes. So the universal example was a simple random walk. And if you remember, how we described it was x_t minus x_(t-1), was either 1 or minus 1, probability half each. This was how we described it. And if you think about it, this is a slightly indirect way of describing the process. You're not describing the probability of this process following this path, it's like a path. Instead what you're doing is, you're describing the probability of this event happening. From time t to t plus 1, what is the probability that it will go down? And at each step you describe the probability altogether, when you combine them, you get the probability distribution over the process. But you can't do it for continuous time, right? The time variable is continuous so you can't just take intervals t and interval t prime and describe the difference. If you want to do that, you have to do it infinitely many times. You have to do it for all possible values. That's the first difficulty. Actually, that's the main difficulty. And how can we handle this? It's not an easy question. And you'll see a very indirect way to handle it. It's somewhat in the spirit of this thing. But it's not like you draw some path to describe a probability density of this path. That's the omega. What is the probability density at omega? Of course, it's not a discrete variable so you have a probability density function, not a probability mass function. In fact, can we even write it down? You'll later see that we won't even be able to write this down. So just have this in mind and you'll see what I was trying to say. So finally, I get to talk about Brownian processes, Brownian motion. Some outside speakers already started talking about it. I wish I already was able to cover it before they talked about it, but you'll see a lot more from now. And let's see what it actually is. So it's described as the following, it actually follows from a theorem. There exists a probability distribution over the set of continuous functions from positive reals to the reals such that first, B(0) is always 0. So probability of B(0) is equal to 0 is 1. Number two-- we call this stationary. For all s and t, B(t) minus B(s) has normal distribution with mean 0 and variance t minus s. And the third-- independent increment. That means if intervals [s i, t i] are not overlapping, then B(t_i) minus B(s_i) are independent. So it's actually a theorem saying that there is some strange probability distribution over the continuous functions from positive reals-- non-negative reals-- to the reals. So if you look at some continuous function, this theorem gives you a probability distribution. It describes the probability of this path happening. It doesn't really describe it. It just says that there exists some distribution such that it always starts at 0 and it's continuous. Second, the distribution for all fixed s and t, the distribution of this difference is normally distributed with mean 0 and variance t minus s, which scales according to the time. And then third, independent increment means what happened between this interval, [s1, t1], and [s2, t2], this part and this part, is independent as long as intervals do not overlap. It sounds very similar to the simple random walk. But the reason we have to do this very complicated process is because the time is continuous. You can't really describe at each time what's happening. Instead, what you're describing is over all possible intervals what's happening. When you have a fixed interval, it describes the probability distribution. And then when you have several intervals, as long as they don't overlap, they're independent. OK? And then by this theorem, we call this probability distribution a Brownian motion. So probability distribution, the definition, distribution given by this theorem is called the Brownian motion. That's why I'm saying it's indirect. I'm not saying Brownian motion is this probability distribution. It satisfies these conditions, but we are reversing it. Actually, we have these properties in mind. We're not sure if such a probability distribution even exists or not. And actually this theorem is very, very difficult. I don't know how to prove it right now. I have to go through a book. And even graduate probability courses usually don't cover it because it's really technical. That means this just shows how continuous time stochastic processes can be so much more complicated than discrete time. Then why are you-- why are we studying continuous time processes when it's so complicated? Well, you'll see in the next few lectures. Any questions? OK. So let's go through this a little bit more. AUDIENCE: Excuse me. PROFESSOR: Yes. AUDIENCE: So when you talk about the probability distribution, what's the underlying space? Is it the space of-- PROFESSOR: Yes, that's a very good question. The space is the space of all functions. That means it's a space of all possible paths, if you want to think about it this way. Just think about all possible ways your variable can evolve over time. And for some fixed drawing for this path, there's some probability that this path will happen. It's not the probability spaces that you have been looking at. It's not one point-- well, a point is now a path. And your probability distribution is given over paths, not for a fixed point. And that's also a reason why it makes it so complicated. Other questions? So the main thing you have to remember-- well, intuitively you will just know it. But one thing you want to try to remember is this property. As your time scales, what happens between that interval is it's like a normal variable. So this is a collection of a bunch of normal variables. And the mean is always 0, but the variance is determined by the length of your interval. Exactly that will be the variance. So try to remember this property. A few more things, it has a lot of different names. It's also called Wiener process. And let's see, there was one more. Is there another name for it? I thought I had one more name in mind, but maybe not. AUDIENCE: Norbert Wiener was an MIT professor. PROFESSOR: Oh, yeah. That's important. AUDIENCE: Of course. PROFESSOR: Yeah, a professor at MIT. But apparently he wasn't the first person who discovered this process. I was some other person in 1900. And actually, in the first paper that appeared, of course, they didn't know about each other's result. In that paper the reason he studied this was to evaluate stock prices and auction prices. And here's another slightly different description, maybe a more intuitive description of the Brownian motion. So here is this philosophy. Philosophy is that Brownian motion is the limit of simple random walks. The limit-- it's a very vague concept. You'll see what I mean by this. So fix a time interval of 0 up to 1 and slice it into very small pieces. So I'll say, into n pieces. 1 over n, 2 over n, 3 over n, dot dot dot, to n minus 1 over n. And consider a simple random walk, n-step simple random walk. So from time 0 you go up or down, up or down. Then you get something like that. OK? So let me be a little bit more precise. Let Y_0, Y_1, to Y_n, be a simple random walk, and let Z be the function such that at time t over n, we let it to be Y of t. That's exactly just written down in formula what it means. So this process is Z. I take a simple random walk and scale it so that it goes from time 0 to time 1. And then in the intermediate values-- for values that are not this, just linearly extended-- linearly extend in intermediate values. It's a complicated way of saying just connect the dots. And take n to infinity. Then the resulting distribution is a Brownian motion. So mathematically, that's just saying the limit of simple random walks is a Brownian motion. But it's more than that. That means if you have some suspicion that some physical quantity follows a Brownian motion, and then you observe the variable at discrete times at very, very fine scales-- so you observe it really, really often, like a million times in one second. Then once you see-- if you see that and take it to the limit, it looks like a Brownian motion. Then now you can conclude that it's a Brownian motion. What I'm trying to say is this continuous time process, whatever the strange thing is, it follows from something from a discrete world. It's not something new. It's the limit of these objects that you already now. So this tells you that it might be a reasonable model for stock prices because for stock prices, no matter how-- there's only a finite amount of time scale that you can observe the prices. But still, if you observe it infinitely as much as you can, and the distribution looks like a Brownian motion, then you can use a Brownian motion to model it. So it's not only the theoretical observation. It also has implication when you want to use Brownian motion as a physical model for some quantity. It also tells you why Brownian motion might appear in some situations. So here's an example. Here's a completely different context where Brownian motion was discovered, and why it has the name Brownian motion. So a botanist-- I don't know if I'm pronouncing it correctly-- named Brown in the 1800s, what he did was he observed a pollen particle in water. So you have a cup of water and there's some pollen. Of course you have gravity that pulls the pollen down. And pollen is heavier than water so eventually it will go down, eventually. But that only explains the vertical action, it will only go down. But in fact, if you observe what's happening, it just bounces back and forth crazily until it finally reaches down the bottom of your cup. And this motion, if you just look at a two-dimension picture, it's a Brownian motion to the left and right. So it moves as according to Brownian motion. Well, first of all, I should say a little bit more. What Brown did was he observed it. He wasn't able to explain the horizontal actions because he only understood gravity, but then people tried to explain it. They suspected that it was the water molecules that caused this action, but weren't able to really explain it. But the first person to actually rigorously explain it was, surprisingly, Einstein, that relativity guy, that famous guy. So I was really surprised. He's really smart, apparently. And why? So why will this follow a Brownian motion? Why is it a reasonable model? And this gives you a fairly good reason for that. This description, where it's the limit of simple random walks. Because if you think about it, what's happening is there is a big molecule that you can observe, this big particle. But inside there's tiny water molecules, tiny ones that don't really see, but it's filling the space. And they're just moving crazily. Even though the water looks still, what's really happening is these water molecules are just crazily moving inside the cup. And each water molecule, when they collide with the pollen, it will change the action of the pollen a little bit, by a tiny amount. So if you think about each collision as one step, then each step will either push this pollen to the left or to the right by some tiny amount. And it just accumulates over time. So you're looking at a very, very fine time scale. Of course, the times will differ a little bit, but let's just forget about it, assume that it's uniform. And at each time it just pushes to the left or right by a tiny amount. And you look at what accumulates, as we saw, the limit of a simple random walk is a Brownian motion. And that tells you why we should get something like a Brownian motion here. So the action of pollen particle is determined by infinitesimal-- I don't know if that's the right word-- but just, quote, ""infinitesimal"" interactions with water molecules. That explains, at least intuitively, why it follows Brownian motion. And the second example is-- any questions here-- is stock prices. At least to give you some reasonable reason, some reason that Brownian motion is not so bad a model for stock prices. Because if you look at a stock price, S, the price is determined by buying actions or selling actions. Each action kind of pulls down the price or pulls up the price, pushes down the price or pulls up the price. And if you look at very, very tiny scales, what's happening is at a very tiny amount they will go up or down. Of course, it doesn't go up and down by a uniform amount, but just forget about that technicality. It just bounces back and forth infinitely often, and then you're taking these tiny scales to be tinier, so very, very small. So again, you see this limiting picture. Where you have a discrete-- something looking like a random walk, and you take t as infinity. So if that's the only action causing the price, then Brownian motion will be the right model to use. Of course, there are many other things involved which makes this deviate from Brownian motion, but at least, theoretically, it's a good starting point. Any questions? OK. So you saw Brownian motion. You already know that it's used in the financial market a lot. It's also being used in science and other fields like that. And really big names, like Einstein, is involved. So it's a really, really important theoretical thing. Now that you've learned it, it's time to get used to it. So I'll tell you some properties, and actually prove a little bit-- just some propositions to show you some properties. Some of them are quite surprising if you never saw it before. OK. So here are some properties. Crosses the x-axis infinitely often, or I should say the t-axis. Because you start from 0, it will never go to infinity, or get to negative infinity. It will always go balanced positive and negative infinitely often. And the second, it does not deviate too much from t equals y squared. We'll call this y. Now, this is a very vague statement. What I'm trying to say is draw this curve as this. If you start at time 0, at some time t_0, the probability distribution here is given as a normal random variable with mean 0 and variance t_0. And because of that, the standard deviation is square root t_0. So the typical value will be around the standard deviation. And it won't deviate. It can be 100 times this. It won't really be a million times that or something. So most likely it will look something like that. So it plays around this curve a lot, but it crosses the axis infinitely often. It goes back and forth. What else? The third one is quite really interesting. It's more theoretical interest, but it also has real-life implications. It's not differentiable anywhere. It's nowhere differentiable. So this curve, whatever that curve is, it's a continuous path, but it's nowhere differentiable, really surprising. It's hard to imagine even one such path. What it's saying is if you take one path according to this probability distribution, then more than likely you'll obtain a path which is nowhere differentiable. That just sounds nice, but why it does it matter? It matters because we can't use calculus anymore. Because all the theory of calculus is based on differentiation. However, our paths have some nice things, it's universal, and it appears in very different contexts. But if you want to do analysis on it, it's just not differentiable. So the standard tools of calculus can't be used here, which is quite unfortunate if you think about it. You have this nice model, which can describe many things, you can't really do analysis on it. We'll later see that actually there is a variant, a different calculus that works. And I'm sure many of you would have heard about it. It's called Ito's calculus. So we have this nice object. Unfortunately, it's not differentiable, so the standard calculus does not work here. However, there is a modified version of calculus called Ito's calculus, which extends the classical calculus to this setting. And it's really powerful and it's really cool. But unfortunately, we don't have that much time to cover it. I will only be able to tell you really basic properties and basic computations of it. And you'll see how this calculus is being used in the financial world in the coming-up lectures. But before going into Ito's calculus, let's talk about the property of Brownian motion a little bit because we have to get used to it. Suppose I'm using it as a model of a stock price. So I'm using-- use Brownian motion as a model for stock price-- say, daily stock price. The market opens at 9:30 AM. It closes at 4:00 PM. It starts at some price, and then moves according to the Brownian motion. And then you want to obtain the distribution of the min value and the max value for the stock. So these are very useful statistics. So a daily stock price, what will the minimum and the maximum-- what will the distribution of those be? So let's compute it. We can actually compute it. What we want to do is-- I'll just compute the maximum. I want to compute this thing over s smaller than t of the Brownian motion. So I define this new process from the Brownian motion, and I want to compute the distribution of this new stochastic process. And here's the theorem. So for all t, the probability that you have M(t) greater than a and positive a is equal to 2 times the probability that you have the Brownian motion greater than a. It's quite surprising. If you just look at this, there's no reason to expect that such a nice formula should exist at all. And notice that maximum is always at least 0, so we don't have to worry about negative values. It starts at 0. How do we prove it? Proof. Take this tau. It's a stopping time, if you remember what it is. It's a minimum value of t such that the Brownian motion at time t is equal to a. That's a complicated way of saying, just record the first time you hit the line a. Line a, with some Brownian motion, and you record this time. That will be your tau of a. So now here's some strange thing. The probability that B(t), B(tau_a), given this-- OK. So what this is saying is, if you're interested at time t, if your tau_a happened before time t, so if your Brownian motion hit the line a before time t, then afterwards you have the same probability of ending up above a and ending up below a. The reason is because you can just reflect the path. Whatever path that ends over a, you can reflect it to obtain a path that ends below a. And by symmetry, you just have this property. Well, it's not obvious how you'll use this right now. And then we're almost done. The probability that maximum at time t is greater than a that's equal to the probability that you're stopping time is less than t, just by definition. And that's equal to the probability that B(t) minus B(tau_a) is positive given tau a is less than t-- Because if you know that tau is less than t, there's only two possible ways. You can either go up afterwards, or you can go down afterwards. But these two are the same probability. What you obtain is 2 times the probability that-- and that's just equal to 2 times the probability that B(t) is greater than a. What happened? Some magic happened. First of all, these two are the same because of this property by symmetry. Then from here to here, B(tau_a) is always equal to a, as long as tau_a is less than t. This is just-- I rewrote this as a, and I got this thing. And then I can just remove this because if I already know that tau_a is less than t-- order is reversed. If I already know that B at time t is greater than a, then I know that tau is less than t. Because if you want to reach a because of continuity, if you want to go over a, you have to reach a at some point. That means you hit a before time t. So that event is already inside that event. And you just get rid of it. Sorry, all this should be-- something looks weird. Not conditioned. OK. That makes more sense. Just the intersection of two properties. Any questions here? So again, you just want to compute the probability that the maximum is greater than a at time t. In other words, just by definition of tau_a, that's equal to the problem that tau_a is less than t. And if tau_a is less than t, afterwards, depending on afterwards what happens, it increases or decreases. So there's only two possibilities. It increases or it decreases. But these two events have the same probability because of this property. Here's a bar and that's an intersection. But it doesn't matter, because if you have the B of X_1 bar y equals B of x_2 bar y then probability of X_1 intersection Y over probability of Y is equal to-- these two cancel. So this bar can just be replaced by intersection. That means these two events have the same probability. So you can just take one. What I'm going to take is one that goes above 0. So after tau_a, it accumulates more value. And if you rewrite it, what that means is just B_t is greater than a given that tau_a is less than t. But now that just became redundant. Because if you already know that B(t) is greater than a, tau_a has to be less than t. And that's just the conclusion. And it's just some nice result about the maximum over some time interval. And actually, I think Peter uses distribution in your lecture, right? AUDIENCE: Yes. [INAUDIBLE] is that the distribution of the max minus the movement of the Brownian motion. And use that range of the process as a scaling for [INAUDIBLE] and get more precise measures of volatility than just using, say, the close-to-close price [INAUDIBLE]. PROFESSOR: Yeah. That was one property. And another property is-- and that's what I already told you, but I'm going to prove this. So at each time the Brownian motion is not differentiable at that time with probability equal to 1. Well, not very strictly, but I will use this theorem to prove it. OK? Suppose the Brownian motion has a differentiation at time t and it's equal to a. Then what you just see is that the Brownian motion at time t plus epsilon, minus Brownian motion at time t, has to be less than or equal to epsilon times a. Not precisely, so I'll say just almost. Can make it mathematically rigorous. But what I'm trying to say here is by-- is it mean value theorem? So from t to t plus epsilon, you expect to gain a times epsilon. That's-- OK? You should have this-- then. In fact, for all epsilon. Greater than epsilon prime'. Let's write it like that. So in other words, the maximum in this interval, B(t+epsilon) minus t, this distribution is the same as the maximum at epsilon prime. That has to be less than epsilon times A. So what I'm trying to say is if this differentiable, depending on the slope, your Brownian motion should have always been inside this cone from t up to time t plus epsilon. If you draw this slope, it must have been inside this cone. I'm trying to say that this cannot happen. From here to here, it should have passed this line at some point. OK? So to do that I'm looking at the distribution of the maximum value over this time interval. And I want to say that it's even greater than that. So if your maximum is greater than that, you definitely can't have this control. So if differentiable, then maximum of epsilon prime-- the maximum of epsilon, actually, and just compute it. So the probability that M epsilon is less than epsilon*A is equal to 2 times the probability of that, the Brownian motion at epsilon is less than or equal to a. This has normal distribution. And if you normalize it to N(0, 1), divide by the standard deviation so you get the square root of epsilon A. As epsilon goes to 0, this goes to 0. That means this goes to half. The whole thing goes to 1. What am I missing? I did something wrong. I flipped it. This is greater. Now, if you combine it, if it was differentiable, your maximum should have been less than epsilon*A. But what we saw here is your maximum is always greater than that epsilon times A. With probability 1, you take epsilon goes to 0. Any questions? OK. So those are some interesting things, properties of Brownian motion that I want to talk about. I have one final thing, and this one it's really important theoretically. And also, it will be the main lemma for Ito's calculus. So the theorem is called quadratic variation. And it's something that doesn't happen that often. So let 0-- let me write it down even more clear. Now that's something strange. Let me just first parse it before proving it. Think about it as just a function, function f. What is this quantity? This quantity means that from 0 up to time T, you chop it up into n pieces. You get T over n, 2T over n, 3T over n, and you look at the function. The difference between each consecutive points, record these differences, and then square it. And you sum it as n goes to infinity. So you take smaller and smaller scales take it to infinity. What the theorem says is for Brownian motion this goes to T, the limit. Why is this something strange? Assume f is a lot better function. Assume f is continuously differentiable. That means it's differentiable, and its differentiation is continuous. Derivative is continuous. Then let's compute the exact same property, exact same thing. I'll just call this-- maybe i will be better. This time t_i and time t_(i-1), then the sum over i of f at t_(i+1) minus f at t_i. If you square it, this is at most sum from i equal 1 to n, f of t_(i+1) minus f of t_i, times-- by mean value theorem-- f prime of s_i. So by mean value theorem, there exists a point s_i such that f(t_(i+1)) minus f(t_i) is equal to f prime s_i, times that. s_i belongs to that interval. Yes. And then you take this term out. You take the maximum, from 0 up to t, f prime of s squared, times i equal 1 to n, t_(i+1) minus t_i squared. This thing is T over n because we chopped it up into n intervals. Each consecutive difference is T over n. If you square it, that's equal to T squared over n squared. If you had n of them, you get T squared over n. So you get whatever that maximum is times T squared over n. If you take n to infinity, that goes to 0. So if you have a reasonable function, which is differentiable, this variation-- this is called the quadratic variation-- quadratic variation is 0. So all these classical functions that you've been studying will not even have this quadratic variation. But for Brownian motion, what's happening is it just bounced back and forth too much. Even if you scale it smaller and smaller, the variation is big enough to accumulate. They won't disappear like if it was a differentiable function. And that pretty much-- it's a slightly stronger version than this that it's not differentiable. We saw that it's not differentiable. And this a different way of saying that it's not differentiable. It has very important implications. And another way to write it is-- so here's a difference of B, it's dB squared is equal to dt. So if you take the differential-- whatever that means-- if you take the infinitesimal difference of each side, this part is just dB squared, the Brownian motion difference squared; this part is d of t. And that we'll see again. But before that, let's just prove this theorem. So we're looking at the sum of B of t_(i+1), minus B of t_i, squared. Where t of i is i over n times the time. From 1 to n-- 0 to n minus 1. OK. What's the distribution of this? AUDIENCE: Normal. PROFESSOR: Normal, meaning 0, variance t_(i+1) minus t_i. But that was just T over n. Is the distribution. So I'll write it like this. You sum from i equal 1 to n minus 1, X_i squared for X_i is normal variable. OK? And what's the expectation of X_i squared? It's T squared over n squared. OK. So maybe it's better to write it like this. So I'll just write it again-- the sum from i equals 0 to n minus 1 of random variables Y_i, such that expectation of Y_i-- AUDIENCE: [INAUDIBLE]. PROFESSOR: Did I make a mistake somewhere? AUDIENCE: The expected value of X_i squared is the variance. PROFESSOR: It's T over n. Oh, yeah, you're right. Thank you. OK. So divide by n and multiply by n. What is this? What will this go to? AUDIENCE: [INAUDIBLE]. PROFESSOR: No. Remember strong law of large numbers. You have a bunch of random variables, which are independent, identically distributed, and mean T over n. You sum n of them and divide by n. You know that it just converges to T over n, just this one number. It doesn't-- it's a distribution, but most of the time it's just T over n. OK? If you take-- that's equal to T, because these are random variables accumulating these squared terms. That's what's happened. Just a nice application of strong law of large numbers, or just law of large numbers. To be precise, you'll have to use strong law of large numbers. OK. So I think that's enough for Brownian motion. And final question? OK. Now, let's move on-- AUDIENCE: I have a question. PROFESSOR: Yes. AUDIENCE: So this [INAUDIBLE], is it for all Brownian motions B? PROFESSOR: Oh, yeah. That's a good question. This is what happens with probability one. So always-- I'll just say always. It's not a very strict sense. But if you take one path according to the Brownian motion, in that path you'll have this. No matter what path you get, it always happens. AUDIENCE: With probability one. PROFESSOR: With probability one. So there's a hiding statement-- with probability. And you'll see why you need this with probability one is because we're using this probability statement here. But for all practical means, like with probability one just means always. Now, I want to motivate Ito's calculus. First of all, this. So now, I was saying that Brownian motion, at least, is not so bad a model for stock prices. But if you remember what I said before, and what people are actually doing, a better way to describe it is instead of the differences being a normal distribution, what we want is the percentile difference. So for stock prices we want the percentile difference to be normally distributed. In other words, you want to find the distribution of S_t such that the difference of S_t divided by S_t is a normal distribution. So it's like a Brownian motion. That's the differential equation for it. So the percentile difference follows Brownian motion. That's what it's saying. Question, is S_t equal to e sub B_t? Because in classical calculus this is not a very absurd thing to say. If you differentiate each side, what you get is dS_t equals e to the B_t, times dB_t. That's S_t times dB_t. It doesn't look that wrong. Actually, it looks right, but it's wrong. For reasons that you don't know yet, OK? So this is wrong and you'll see why. First of all, Brownian motion is not differentiable. So what does it even mean to say that? And then that means if you want to solve this equation, or in other words, if you want to model this thing, you need something else. And that's where Ito's calculus comes in. OK. I'll try not to rush too much. So suppose-- now we're talking about Ito's calculus-- you want to compute. So here is a motivation. You have a function f. I will call it a very smooth function f. Just think about the best function you can imagine, like an exponential function. Then you have a Brownian motion, and then you apply this function. As an input, you put the Brownian motion inside the input. And you want to estimate the outcome. More precisely, you want to estimate infinitesimal differences. Why will we want to do that? For example, f can be the price of an option. More precisely, let f be this thing. OK. You have some s_0. Up to s_0, the value of f is equal to 0. After s_0, it's just a line with slope 1. Then f of Brownian motion is just the price exercise-- what is it-- value of the option at the expiration. T is the expiration time. It's a call option. That's the call option. So if your stock at time T goes over s_0, you make that much. If it's below s_0, you'll lose that much. More precisely, you have to put it below like that. Let's just do it like that. And it looks like that. So that's like a financial derivative. You have an underlying stock and then some function applies to it. And then what you have, the financial asset you have, actually can be described as this function. A function of an underlying stock, that's called financial derivatives. And then in the mathematical world, it's just a function applied to the underlying financial asset. And then, of course, what you want to do is understand the difference of the value, in terms of the difference of the underlying asset. If B_t was a very nice function as well. If B_t was differentiable, then the classical world calculus tells us that d of f is equal to d of B_t over d of t times dt. Yes. So if you can differentiate it over the time difference, over a small time scale. All we have to do is understand the differentiation. Unfortunately, we can't do that. We cannot do this. Because we don't know what-- we don't even have this differentiation. OK. Try one, take one failed, take two. Second try, OK? This is not differentiable, but still I understand the minuscule difference of dB_t. So what about this? df-- maybe I didn't write something, f prime-- is equal to just dB_t of f prime. OK? What is this? We can't differentiate Brownian motion, but still we understand the minuscule and infinitesimal difference of the Brownian motion. So I just gave up trying to compute the differentiation. But instead, I'm going to just compute how much the Brownian motion changed over this small time scale, this difference, and describe the change of our function in terms of the differentiation of our function f. f is a very good function, so it's differentiable. So we know this. This is computable. This is computable. It's the difference of Brownian motion over a very small time scale. So that at least now is reasonable. We can expect it. It might be true. Here, it didn't make sense at all. Here, it at least make sense, but it's wrong. And why is it wrong? It's precisely because of this. The reason it's wrong, the reason it is not valid is because of the fact dB squared equals dt. And let's see how this comes into play, this factor. I think that will be the last thing that we'll cover today. OK. So if you remember where you got this formula from, you probably won't remember. But from calculus, this follows from Taylor's expansion. f of t plus x, I'll say, is equal to f of t plus f prime of t times x, plus f double prime of t over 2, times x squared plus-- over 3 factorial x cubed plus-- df is just this difference. Over a very small time increase, we want to understand the difference of the function. That's equal to f prime t times x. OK. In classical calculus we were able to ignore all these terms. So in the classical world f(t+x) minus f(t) was about f prime t times x. And that's precisely this formula. But if you use Brownian motion here-- so what I'm trying to say is if B at some time t plus x, minus Brownian motion B at time t, then let's just write down the Taylor formula. We get f prime at B_t. x will be this difference, B at t plus x minus B at t. That's like the difference in B_t. So up to this much we see this formula. And the next term, we get the second derivative of this function over 2 and x squared, x plus this difference. So what we get is dB_t squared. OK? But as you saw, this is no longer ignorable. That is like a dt, as we deduced. And that comes into play. So the correct-- then by Taylor expansion, the right way to do it is df is equal to the first derivative term, dB_t, plus the second derivative term, double prime over 2 dt. This is called Ito's lemma. And now let's say if you want to remember one thing from the math part, try to make it this one. This had great impact. If you follow the logic it makes sense. It's really amazing how somebody came up with for the first time because it all makes sense. It all fits together if you think about it for a long time. But actually, I once saw that Ito's lemma is one of the most cited lemmas, like most cited paper. The paper that's containing this thing. Because people think it's nontrivial. Of course, there are facts that are being used more than this, classical facts, like trigonometric functions, exponential functions. They are being used a lot more than this, but people think that's trivial so they don't cite it in their research and paper. But this, people respect the result. It's a highly nontrivial result. And it's really amazing how just by adding this term, all this theory of calculus all now fit together. Without this-- maybe it's a too strong statement-- but really Brownian motion becomes much more rich because of this fact. Now we can do calculus with it. So there's two things to remember. Well, if you want to remember one thing, that's Ito's lemma. If you want to remember two things, it's just quadratic variation, dB_t squared is equal to dt. And I remember that's exactly because B_t is like a normal variable with 0, t. And time scale-- B_t is like a normal random variable 0, t. dB_t squared is like the variance of it. So it's t, and if you differentiate it, you get dt. That was exactly how we computed it. So, yeah, I'll just quickly go over it again next time just to try to make it stick in to your head. But please, think about it. This is really cool stuff. Of course, because of that computation, calculus using Brownian motion becomes a lot more complicated. Anyway, so I'll see you on Thursday. Any last minute questions? Great."
9,8aesZvl_P_k,Brownian Motion-II,Probability and Stochastics for finance,brownian motion,"As, we have discussed in the last class, we discussed symmetric random walk and how we can scale it slightly up and down and so that we can make it more zigzag and go towards what is called a Brownian motion. So, the Brownian motion is a continuous stochastic process which exhibits the property of a symmetric random walk. So, that is the idea of a Brownian motion. So, for example, if you look at the motion of a pollen grain in water, it would be something like this, more zigzagging than this than, I can draw. So, this is something a motion of a particle in a gas chamber a motion of a molecule. So, Brownian motion encapsulates lot of phenomenon. So, what did I say, the best way to remember about Brownian motion is that, Brownian motion is a continuous analog of symmetric random walk. In a continuous setting, it behaves in the way a symmetric random walk behaves in the discrete setting. So as usual, I will have the probability space which is written down here. So, Brownian motion, so, your stochastic process, Wt some people write W lower index t. it is up to you. it does not matter, is called a Brownian motion, if given any  time points, t is time actually, spreading time points say tm tn whatever. Given any time points like this the increments are independent. The increments mean just like the way you have done increments in the symmetric random walk, the increments Wt1 minus Wt0. Wt0 is actually 0, W0 is 0 just a minute, I think, I should just change it a bit. A stochastic process with W0 is equal to 0. So, it does not matter. Whatever be our scenario omega, W0 is always 0. So, it is identically a zero function. So, W0 itself is a function. Please remember it is a random variable. So, whatever be the form of that random or whatever be this random variable, whatever be the scenario omega, W of that would always be 0. That is the meaning of the whole thing. So, this Wt2 minus Wt1 this random variable, these increments in the random variables. Hence, how much change you are having how basically, you are telling that how much zigzagging has taken place in the interval t2 to t1, t0 to t1, t1 to t2, t2 to t3 and so forth. So, it is some sort of a broad measure of the zigzagging that has taken place. How much the function value has changed at the 2 ends. These are independent random variables. Now the independent random variables. This is one property you know from the property of the symmetric random walk. Also, you know the symmetric random walk, the expectation of increments are 0 and the variance of the increments are the difference between the 2 time end points. Here, actually one can prove through the Central Limit Theorem that, these increments actually follow normal distribution, which we do not prove because, that would take too much of time, it is a very short and compact course. So, these are independent random variables and Wti plus 1 minus Wti, this random variable follows normal distribution, with mean 0 and variance ti plus 1 minus ti. So, if all these properties, 2 properties are followed, first that this has to be maintained whatever be the scenario, whatever be your time points increasing, if you take an increasing set of time points finite set of time points, then these things are independent and these increments themselves follow normal distribution, for every i. Of course, this has to be for every i, now start from i equal to 0 to i equal to n, i equal to n minus 1 basically. So, each of these, is following a normal distribution. So, this is what is called Brownian motion. Does stock price follow Brownian motion? The stock price truly does not follow Brownian motion, though it looks like one. Because Brownian motions can take negative values, because the symmetric random walks can also take negative values, but a stock price can never take negative value. Once a stock price is 0, that stock has to get out of the market now it is a 0-value stock. So, stock prices are not really a model using Brownian motion, but actually these stock prices actually were modeled by Bachelier in 1900, who was the student of Henry Poincare using Brownian motion and showing that the pricing of such commodities in the stock market, of various instruments in the stock market can be achieved by solving the heat equation. So, he linked the processing the financial markets to partial differential equations. And of course, his idea was lost and now later on he has become a very famous name. But the interesting part is that, the way stock market or movements of stock prices are modeled that is called a geometric Brownian motion and then that is built using, that will always give you a nonnegative thing, which is built using a Brownian motion and you can understand and taking the trick that, if you want to get non-negativity always use the exponential function. So, that trick is being played in this area pretty often. So, now we will introduce what is called, if I want to define a filtration associated with a Brownian motion, how do I define a filtration associated with a Brownian motion? So, what I will do in this filtration associated with the Brownian motion. So, this filtration Ft is a collection of Sigma-algebras, this is a collection such that, number one, whenever t is strictly bigger than s F of s must always be contained in Ft, but you have information as time evolves. So, this should always be contained in Ft okay. Now number two, is that Wt must be adapted to the filtration. The Brownian motion must be adapted to the filtration  and the third point is, so if you have this situation then, Wu minus Wt is independent of Ft. That is, once you move beyond t, Ft does not have any information about this. This is independent of what information you have in Ft. Ft can also be viewed in some sense as a smallest Sigma-algebra generated by the stochastic process till a given time. So, take all the values of the random variables omega t, up to a given time and take the Sigma-algebra generated by them, that can be also viewed as one of the filtrations right. You could have larger filtrations also but that is essentially it is. So, once we know that that we can have some filtration defined like this, we can prove that the Brownian motion is a Martingale. So, again, just do like this, take t less than equal to s, so you will find that the tricks are almost similar. So, what I do is, I, and now I breakup the whole thing. You know, Ws is completely determined by Fs is known. So, you have to take out what is known. So, Ws is equal to Ws into 1 you take out the Ws expectation of 1 of constant random variable is the same so. Now here, Wd minus Ws as the third definition, does not depend on Fs. So, it is nothing bu,t it is so there is no conditional expectation here, so is just the expectation, so this random variable is just this constant random variable plus Ws. You take the Ws out, expectation of 1 given Fs expectation of 1 is 1 basically that is it. Because 1, just the constant random variable does not depend on F s but this you know is 0 because of this fact, 0 plus W s which is equal to W s and that proves that it is a Martingale. There are several other Martingales, which are associated with the Brownian motion. A Martingale that we are going to write now, is very-very important in finance specifically in calculation of risk neutral probabilities and all those things. So, this is a very important Martingale called the exponential Martingale. So, the exponential Martingale  is defined like this. So, exportation means, e to the power, so sigma Wt, where sigma is positive number, exponential means e to the power of this. Of course, this itself is a random variable because you are taking exponential to the power of a random variable. So, it is, when you are taking the exponential, exponentiated by a random variable. So, this itself is a random variable. Now the idea is that if you have a filtration associated with respect to Wt then that same filtration will be associated with Zt, because if Wt is adapted to a given filtration Zt will also be adapted to the same filtration, because knowledge of Zt singularly depends on the knowledge of Wt right. The question is whether it is a Martingale. So, one has to prove that this is also a Martingale. So, we start in the similar fashion. This proof is not as straightforward, as this proof, though similar type of approaches would be used but let us just go and do it. This omega, the sigma that you see, this we will finally talk about as volatility of the stock price movement. It captures, how the randomness, captures the massive movement. It really gives you a feel of the zigzagging of the path how the prices are how fast they are going and coming down so that sort of so this captures that idea basically. So, F is a filtration associated with the Brownian motion Wt. Say I have added sigma Ws and subtracted sigma Ws from here. Observe that sigma square t is a nonrandom part. It is not a random variable right. So, here is the product x into y okay. So, the question is, in this sort of situations right, there are some deeper questions. If you go back to your original, where we had written down the laws of conditional expectation, the rules then, we expected this and this, this product has to be integrable because if you have to maintain the definition of conditional expectation. Of course, product has to be integrable means you need to define, what is the meaning of integration of these two random variables okay. Is such random variables are integrable? That is the question we are not going to answer right now. We will later on show that these are actually integral, let alone discuss the integrability of this, that is they are actually integrable random variables, because they will come out to be solution of certain equations. So, and if you have a Brownian motion, how can you integrate it. Can you integrate it just like any other random variable, can you find the expectation of a Brownian motion? The answer is yes. I can find the expectation of this Brownian motion because this is 0. Can you find the expectation of this Brownian motion? The answer is expectation of Brownian this Brownian motion is this, minus half sigma square t. Now it will be left to the reader to decide whether. Of course, there are certain little technical issues, I am not getting into, but it is clear that expect. What is meant by the meaning of ntegrability of a random variable? Integrability means that the expectation is finite. The expectation of this is finite, this is finite. So, this exponential function will have the integral will be integrable and this exponential function would be also integrable. So, at the end if you look at this part. So, this is nothing but this part, but this part this is because, this has mean minus half sigma square t because, this mean is 0 and, this exponential is nothing but a constant thing, so mean of this is nothing but minus half sigma square t so this is a thing with finite mean. Now if you take a you are taking exponentiation so basically you are taking expectation of the exponential function. If the random variable itself has a finite mean, then if you take the exponential function, that exponential function will also have a finite mean it will have finite expectation. That is why it is meaningful to apply the fact that I can take out what is known. You see this part is known to me when, at time s, this whole part is known to me because this only depend this is just the evolution of W the random variable up to the time s. So, I will take this part out. Taking out what is known I will have exponential. So, it is very important to get certain technicalities clear, before you move, where you are actually applying the results correctly. That is an important thing, that one needs to learn as one goes on doing more mathematics. Sometimes we can do some hand waving but not always. Now once, I have this, remember that this thing is independent of Fs, which means, I just need to calculate this. Now what is this, sorry, I would not have the Fs here sorry it is independent. Now if those, who know some probability, they will understand that, I know that Wt minus Ws is a normal distribution with mean 0 and variance t minus s and this is nothing but the moment generating function of a normal distribution. I have not spoken about moment generating function in this discussion, but if you forget about this term moment generating function, you can directly compute this expectation. I am not going to compute for you, this will come as a homework and this will appear in your assignments. So, what I am just writing down the answer. Even this is simple integration, so I am just not going to do that. This is equal to exponential of half sigma square t minus s okay. So, this is what you will have that is the answer. So, once you write that down then, the final answer would be the following, that if you write this as exponential so you write this as exponential sigma Ws minus half sigma square t and then you write this as exponential of sigma square t minus s, so this is nothing but exponential sigma Ws minus half sigma square s so this is nothing but Zs. There is another Martingale which is helpful in finance is the following. It is Zt is W square minus t. So, this will also go as an exercise in your homework assignments, to prove that this is a Martingale. Now we will talk about, so what is happening. We will talk about how to compute the joint probability of a Brownian motion at certain given time points. You take Wt at any t, what is the distribution of this random variable. Wt can be always written as, Wt minus W0 and this has normal 0t. So, if you want to know whether, at a given time t your Wt is lying between some points a and b, it is obvious you can just use the basic idea that is. The question is, suppose I have now n time points which are greater than 0, 0 I know where it is, so with n time points and we ask you the question, how to find sorry, say Wt1, how do I do it. So, let me look at the case at the very first, this is how you compute what are called the transition probability densities let us see. So, now suppose, you are given the information that, under the given scenario Wt1, under the given scenario omega Wt1 omega was x okay. So, suppose I know that it is known to me that, at t1 for the given scenario W, at time t1 it was x where say x1, x1 lying between b1 and a1. So, what I now want to do is, I want to calculate the probability at W t2 lies between a2 and b2 given that Wt1 is x1. That is what I want to do. But, if you see, if I fixed Wt1 as x1 then, what do I have. I have Wt2 minus x1 as my random variable, x1 is known to me that, at time t1 x1 is what happened. So, now what is the probability that Wt2 would lie between the value of Wt2 for the given scenario omega will lie between a2 and b2. So, for the scenario omega t1 I know what will happen. It was at x1. Now find so it is in the state x1 so what is the probability that, the next state would lie between a2 and b2. It is like sort of a computing transition probabilities. So, here if you look at this thing, the expectation of this, this is also normal random variable, so this also follows normal random variable, but the expectation of this, is what, expectation is, so it is a, see here, we had, so this new random variable z, so Wt2 so, is equal to z plus x1. So, under this given information the expectation of Wt2. So, Wt2 under this information follows normal x1 with, because this is the time t1, so this z follows normal 0 at time t2 t1, so Wt2 is nothing but x1 plus z. So, Wt2 follows this one, because this expectation is 0. So, once you know this fact then what would happen. This means now I can compute, sorry, I should be having, so we will be applying the same idea of conditional probability, that probability of A Intersection B is probability of A into probability of B sorry, so probability of A given B is probability of A intersection B by probability of B. This is what we had learnt. So, you can always write probability of A Intersection B is probability of A given B into probability of B. That is exactly what we are going to do here. So first we are computing the conditional expectation and then using this we will write the joint probability. So, this conditional expectation is, 1 by the conditional probability is, 1 by x2 is the variable that I am using for the variable x2, x1 is what is the mean. Now, if I want to write the joint probability so this is my conditional density. This is my conditional density function and thus I can write the conditional density function in a more simpler way. So, I can write the conditional density function in a compact form but let us do a general form and then we will tell you how to write the conditional density function. If you look at this, now I am writing this one, is a joint probability okay, and this is equal to, so first I will write, I will tell you, what is the meaning of this. So, these are the marginal probabilities, a marginal densities. So, the marginal density, in general is given like this. So, what is the density function associated with the fact my current state is y and then in time t, I will move to the state x, at time 0 say if my current stated time 0 is y in time t, I will move to the state x, what is the density function associated with that particular transition. So, this is called the transitional density function or the conditional density, transition density and that is given as, one by root 2 pi t, e to the power of minus x minus y whole square by 2t . So, this is my conditional density function. So, I would keep it as an exercise for you to write down for the case till end. How can you write it? So, here you see, from 0 my state was 0, it is always 0, W0, 0. I have come to the state X1 at t1. Given that, I am in state x1 at t1, within the time t1 to t2, I have, within the time span t2 minus t1, I have come to the state x2. So, essential a marco process. Brownian motion is also a marco process those who know about marco process. So, we are just trying to compute, this is nothing but a conditional, this is a transitional probability actually. It tells you, given the state is at x1, what is the probability that the state is between a2 and b2 so next state. Because it is a continuous thing, you cannot say that probability Wt2 is x2 because that will become 0, so you just have to say what is in between. So, that is the whole thing. So, I know what is at 0 I will come to the state x1. So, the conditional density at x1 is the conditional density at x2. I am at time t1 and I am at x1 and at time t2, so within the time spend t2 minus t1 I have come to x2 then what is the conditional density. So, the joint integration of this, would give me the conditional probability, which can be motivated, is motivated from this very basic idea. Thank you very much."
